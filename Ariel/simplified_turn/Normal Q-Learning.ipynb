{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DQN Agent\n",
    "====\n",
    "Code taken from PyTorch DQN tutorial, then modified to work on our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_drone\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "#device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intialize environment along with the matplotlib figure.\n",
    "- DroneCardinal-v0 is the name of the environment to initialize\n",
    "- Rows and columns determine the shape of the environment area\n",
    "- Memory capacity says how many of the last steps shall be remembered and displayed when rendering with 'notebook' mode.\n",
    "- Ax takes a matplotlib plot, which it will plot to if given, otherwise plot to the default pyplot. This makes it so we can have the rendering of the playing as a matplotlib subplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, array([9, 7, 5, 8]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x1008 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2)\n",
    "fig.set_figwidth(30)\n",
    "fig.set_figheight(14)\n",
    "\n",
    "grid_shape = (40, 40)\n",
    "env = gym.make('Waypoint-v0',\n",
    "               rows=grid_shape[0],\n",
    "               columns=grid_shape[1],\n",
    "               memory_capacity=50,\n",
    "               ax=ax[1][0]).unwrapped\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the ReplayMemory object type. \n",
    "\n",
    "It is how transitions in the environment is stored, and randomly given back with the sample function, to train the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    #T.Resize(40, interpolation=Image.CUBIC),\n",
    "                    #T.Resize(40),\n",
    "                    T.Resize(40),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "pos_blur_size = 10\n",
    "goal_blur_size = 10\n",
    "white_channel = np.zeros(grid_shape)\n",
    "\n",
    "screen = env.render(mode='rgb_array')\n",
    "last_drone_pos = tuple(env._get_obs()[:2])\n",
    "last_goal_pos = tuple(env._get_obs()[2:])\n",
    "def get_screen(new_episode=False):\n",
    "    global screen, last_drone_pos, last_goal_pos\n",
    "    drone_pos = tuple(env._get_obs()[:2])\n",
    "    goal_pos = tuple(env._get_obs()[2:])\n",
    "    \n",
    "    if new_episode:\n",
    "        screen = env.render(mode='rgb_array')\n",
    "        screen[:, :, 0] = white_channel\n",
    "        deblur_position(last_goal_pos, goal_blur_size, 2)\n",
    "        blur_position(goal_pos, goal_blur_size, 2)\n",
    "        last_goal_pos = goal_pos\n",
    "    \n",
    "    deblur_position(last_drone_pos, pos_blur_size, 1)\n",
    "    blur_position(drone_pos, pos_blur_size, 1)\n",
    "    \n",
    "    last_drone_pos = drone_pos\n",
    "    last_goal_pos = goal_pos\n",
    "    \n",
    "    # blur grid\n",
    "    #screen = blur_grid(screen)\n",
    "    # recenter around drone\n",
    "    #screen = recenter_grid_on_position(screen)\n",
    "    # set the red channel (height) to zero\n",
    "    \n",
    "    output = screen.transpose((2, 0, 1))\n",
    "    _, screen_height, screen_width = output.shape\n",
    "    output = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    output = torch.from_numpy(output)\n",
    "    output = output.type(torch.FloatTensor)\n",
    "    return resize(screen).unsqueeze(0).to(device)\n",
    "\n",
    "def blur_position(position, blur_radius, channel):\n",
    "    global screen\n",
    "    size_x, size_y = screen[:, :, channel].shape\n",
    "    for d_x in range(blur_radius * 2 + 1):\n",
    "        d_x -= blur_radius\n",
    "        for d_y in range(blur_radius * 2 + 1):\n",
    "            d_y -= blur_radius\n",
    "            # If the distance to the point is greater than the\n",
    "            # distance to be blurred, skip this cell.\n",
    "            distance = abs(d_x) + abs(d_y)\n",
    "            if distance > blur_radius:\n",
    "                continue\n",
    "            x, y = position\n",
    "            x += d_x\n",
    "            y += d_y\n",
    "            # Check if index is inside grid\n",
    "            if x < 0 or x >= size_x or y < 0 or y >= size_y:\n",
    "                continue\n",
    "            screen[x, y, channel] = 255 / (distance + 1)\n",
    "            \n",
    "def deblur_position(position, blur_radius, channel):\n",
    "    global screen\n",
    "    size_x, size_y = screen[:, :, channel].shape\n",
    "    for d_x in range(blur_radius * 2 + 1):\n",
    "        d_x -= blur_radius\n",
    "        for d_y in range(blur_radius * 2 + 1):\n",
    "            d_y -= blur_radius\n",
    "            x, y = position\n",
    "            x += d_x\n",
    "            y += d_y\n",
    "            # Check if index is inside grid\n",
    "            if x < 0 or x >= size_x or y < 0 or y >= size_y:\n",
    "                continue\n",
    "            screen[x, y, channel] = 0\n",
    "\n",
    "def recenter_grid_on_position(rgb_array):\n",
    "    rows, columns = grid_shape\n",
    "    drone_pos = env._drone_pos\n",
    "    drone_x, drone_y = drone_pos\n",
    "    offset_x = (columns - 1) - drone_x\n",
    "    offset_y = (rows - 1) - drone_y\n",
    "    \n",
    "    new_grid = np.zeros((rows * 2 - 1, columns * 2 - 1, 3)) + 255\n",
    "    for x, column in enumerate(rgb_array):\n",
    "        for y, row in enumerate(column):\n",
    "            for channel, cell in enumerate(row):\n",
    "                #new_grid[x + offset_x, y + offset_y, channel] = #rgb_array[x, y, channel]\n",
    "                new_grid[x + offset_x, y + offset_y, channel] = cell\n",
    "    return new_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.swapaxes(np.swapaxes(np.squeeze(np.asarray(get_screen().cpu()), 0), 0, 2), 0, 1))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.step(1)\n",
    "plt.imshow(env.render(mode='rgb_array'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.9\n",
    "#GAMMA = 0.1\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.2\n",
    "#EPS_END = 0.0\n",
    "EPS_DECAY = 40000\n",
    "TARGET_UPDATE = 10\n",
    "\n",
    "# Get screen size so that we can initialize layers correctly based on shape\n",
    "# returned from AI gym. Typical dimensions at this point are close to 3x40x90\n",
    "# which is the result of a clamped and down-scaled render buffer in get_screen()\n",
    "init_screen = env.render(mode='rgb_array')\n",
    "screen_height, screen_width, _ = init_screen.shape\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "#policy_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "#target_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "#target_net.load_state_dict(policy_net.state_dict())\n",
    "#target_net.eval()\n",
    "\n",
    "#optimizer = optim.RMSprop(policy_net.parameters())\n",
    "#memory = ReplayMemory(10000)\n",
    "\n",
    "# Reset these whenever \n",
    "episode_durations = []\n",
    "episode_rewards = []\n",
    "episode_best_reward = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_done = 0\n",
    "def select_action(state):\n",
    "    global steps_done, q_table\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        state = get_state()\n",
    "        return np.argmax(q_table[state])\n",
    "    else:\n",
    "        return random.randrange(n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_durations = []\n",
    "episode_rewards = []\n",
    "episode_best_reward = []\n",
    "def plot_durations():\n",
    "    # Plot episode durations\n",
    "    ax[0][0].cla()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    ax[0][0].set_xlabel('Episode')\n",
    "    ax[0][0].set_ylabel('Duration')\n",
    "    ax[0][0].plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        ax[0][0].plot(means.numpy())\n",
    "        \n",
    "    # Plot episode rewards\n",
    "    ax[0][1].cla()\n",
    "    rewards_t = torch.tensor(episode_rewards, dtype=torch.float)\n",
    "    best_rewards_t = torch.tensor(episode_best_reward, dtype=torch.float)\n",
    "    ax[0][1].set_xlabel('Episode')\n",
    "    ax[0][1].set_ylabel('Reward')\n",
    "    ax[0][1].plot(rewards_t.numpy())\n",
    "    ax[0][1].plot(best_rewards_t.numpy())\n",
    "    if len(rewards_t) >= 100:\n",
    "        means = rewards_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        ax[0][1].plot(means.numpy())\n",
    "    \n",
    "    # Plot environment\n",
    "    env.render()\n",
    "\n",
    "    # Plot environment as seen by the agent\n",
    "    ax[1][1].imshow(np.swapaxes(np.swapaxes(np.squeeze(np.asarray(get_screen().cpu()), 0), 0, 2), 0, 1))\n",
    "    ax[1][1].axis('off')\n",
    "    \n",
    "    # pause a bit so that plots are updated\n",
    "    plt.pause(0.001)\n",
    "    if is_ipython:\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-Learning thing\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "encode() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0e69c0ec7179>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mq_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: encode() takes 1 positional argument but 3 were given"
     ]
    }
   ],
   "source": [
    "#possible_start_points = [(5,5), (grid_shape[0] - 5, 5), (5, grid_shape[1] - 5), (grid_shape[0] - 5, grid_shape[1] - 5)]\n",
    "LEARNING_RATE = 0.25\n",
    "\n",
    "obs_space = [env.observation_space[0].n] + list(env.observation_space[1].nvec)\n",
    "def encode(state_tuple):\n",
    "    state = [state[0]] + list(state[1])\n",
    "    n = 0\n",
    "    for i, o in zip(state, obs_space):\n",
    "        state += i\n",
    "        state *= o\n",
    "    return state\n",
    "#    state = drone_x\n",
    "#    state *= grid_shape[0]\n",
    "#    state += drone_y\n",
    "#    state *= grid_shape[1]\n",
    "#    state += goal_index\n",
    "#    return state\n",
    "\n",
    "#def decode(state):\n",
    "#    out = []\n",
    "#    out.append(state % grid_shape[1])\n",
    "#    state = state // grid_shape[1]\n",
    "#    out.append(state % grid_shape[0])\n",
    "#    state = state // grid_shape[0]\n",
    "#    out.append(state)\n",
    "#    return list(reversed(out))\n",
    "\n",
    "def get_state():\n",
    "    state = env._get_obs()\n",
    "    goal_index = possible_start_points.index(tuple(state[2:]))\n",
    "    return encode(state[0], state[1], goal_index)\n",
    "\n",
    "q_table = np.zeros((encode(grid_shape[0] - 1, grid_shape[1] - 1, 3) + 1, 4)) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                            batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                       if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    loss = F.smooth_l1_loss(state_action_values,\n",
    "                            expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reward Function:\n",
    "===\n",
    "Reward 1 for correct direction, -2 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-535bcfea19b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mhighest_grid_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mlast_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# Select and perform an action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 2)"
     ]
    }
   ],
   "source": [
    "num_episodes = 20000000\n",
    "episode_durations = []\n",
    "episode_rewards = []\n",
    "episode_best_reward = []\n",
    "\n",
    "possible_start_points = [(5,5), (grid_shape[0] - 5, 5), (5, grid_shape[1] - 5), (grid_shape[0] - 5, grid_shape[1] - 5)]\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "    env.reset()\n",
    "    \n",
    "    #env._goal_pos = (5, 5)\n",
    "    #env._goal_pos = random.choice(possible_start_points)\n",
    "    #mistakes = 0\n",
    "    \n",
    "    #state = get_state()\n",
    "    state =env._get_obs()\n",
    "    last_state = state\n",
    "    total_reward = 0\n",
    "    highest_grid_value = np.amax(env._grid)\n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        action = select_action(state)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        # Hijack reward calculation (temporary?)\n",
    "        if (drone_x, drone_y) == (goal_x, goal_y):\n",
    "            reward = np.float64(0)\n",
    "        else:\n",
    "            diff = abs(goal_x - drone_x) + abs(goal_y - drone_y)\n",
    "            last_diff = abs(goal_x - last_x) + abs(goal_y - last_y)\n",
    "            if (last_diff > diff):\n",
    "                reward = np.float64(1)\n",
    "            else:\n",
    "                reward = np.float64(0)\n",
    "\n",
    "        total_reward += reward\n",
    "        if t == 0:\n",
    "            episode_best_reward.append(abs(last_x - goal_x) + abs(last_y - goal_y))\n",
    "        if t > 200:\n",
    "            done = True\n",
    "        if reward == 0:\n",
    "            #done = True\n",
    "            mistakes += 1\n",
    "            if mistakes >= 10:\n",
    "                done = True\n",
    "            pass\n",
    "\n",
    "        # Perform one step of the optimization (on the target network)\n",
    "        #optimize_model()\n",
    "        state = get_state()\n",
    "        q_table[last_state][action] += LEARNING_RATE * (reward + GAMMA * np.amax(q_table[state]) - q_table[last_state][action])\n",
    "        \n",
    "        #print(LEARNING_RATE * (reward + GAMMA * np.amax(q_table[state]) - q_table[last_state][action]))\n",
    "        #print(reward + GAMMA * np.amax(q_table[state]) - q_table[last_state][action])\n",
    "        last_state = state\n",
    "        \n",
    "        #if done or mistakes > 10:\n",
    "        if done:\n",
    "            #print(t + 1)\n",
    "            episode_durations.append(t + 1)\n",
    "            # episode_rewards.append(max(total_reward - mistakes, 0))\n",
    "            episode_rewards.append(max(total_reward - mistakes, 0) / episode_best_reward[-1])\n",
    "            episode_best_reward[-1] = 1\n",
    "            if i_episode % 500 == 0: \n",
    "                plot_durations()\n",
    "            break\n",
    "\n",
    "    # Update the target network, copying all weights and biases in DQN\n",
    "    #if i_episode % TARGET_UPDATE == 0:\n",
    "    #    target_net.load_state_dict(policy_net.state_dict())\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = get_edges(grid)\n",
    "get_cost(dijkstra(edges, (2,5), (0,0)))\n",
    "#path = get_path(dijkstra_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cost(dijkstra(edges, (2,0), (0,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13 16  5 35]\n",
      "[[132 129 125 ...  25  29  32]\n",
      " [129 125 122 ...  22  25  29]\n",
      " [125 122 119 ...  19  22  25]\n",
      " ...\n",
      " [219 216 213 ... 112 116 119]\n",
      " [222 219 216 ... 116 119 122]\n",
      " [225 222 219 ... 119 122 125]]\n"
     ]
    }
   ],
   "source": [
    "test = env.render(mode='rgb_array')\n",
    "print(env._get_obs())\n",
    "\n",
    "def blur_grid(rgb_array):\n",
    "    def lattice_distance(a, b):\n",
    "        a_x, a_y = a\n",
    "        b_x, b_y = b\n",
    "        return abs(a_x - b_x) + abs(a_y - b_y)\n",
    "    \n",
    "    red_channel = rgb_array[:,:,2]\n",
    "    goal = tuple(env._get_obs()[2:])\n",
    "    diagonal = env._grid.shape[0] + env._grid.shape[1] - 1\n",
    "    \n",
    "    for x, column in enumerate(red_channel):\n",
    "        for y, cell in enumerate(column):\n",
    "            distance = lattice_distance((x, y), goal)\n",
    "            red_channel[x][y] = (255 / diagonal) * (distance + 1)\n",
    "    rgb_array[:, :, 2] = red_channel\n",
    "    return rgb_array\n",
    "\n",
    "test = blur_grid(test)\n",
    "print(test[:, :, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

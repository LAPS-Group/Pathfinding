{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DQN Agent\n",
    "====\n",
    "Code taken from PyTorch DQN tutorial, then modified to work on our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_drone\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "#device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intialize environment along with the matplotlib figure.\n",
    "- DroneCardinal-v0 is the name of the environment to initialize\n",
    "- Rows and columns determine the shape of the environment area\n",
    "- Memory capacity says how many of the last steps shall be remembered and displayed when rendering with 'notebook' mode.\n",
    "- Ax takes a matplotlib plot, which it will plot to if given, otherwise plot to the default pyplot. This makes it so we can have the rendering of the playing as a matplotlib subplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, 31, 38, 34, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x1008 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2)\n",
    "fig.set_figwidth(30)\n",
    "fig.set_figheight(14)\n",
    "\n",
    "grid_shape = (40, 40)\n",
    "#grid_shape = (105, 105)\n",
    "env = gym.make('TurnShort-v1',\n",
    "               training_samples=50,\n",
    "               subsampling=10,\n",
    "               steps=2,\n",
    "               turn_rate=4,\n",
    "               training_data_dir='/workspace/training_data/',\n",
    "               ax=ax[1][0]).unwrapped\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up the ReplayMemory object type. \n",
    "\n",
    "It is how transitions in the environment is stored, and randomly given back with the sample function, to train the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network\n",
    "=======\n",
    "The network is a convolutional neural network, which uses ReLu activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, h, w, outputs):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        #self.conv2 = nn.Conv2d(16, 32, kernel_size=4, stride=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Number of Linear input connections depends on output of conv2d layers\n",
    "        # and therefore the input image size, so compute it.\n",
    "        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        linear_input_size = convw * convh * 32\n",
    "        self.head = nn.Linear(linear_input_size, outputs)\n",
    "        #self.head = nn.Linear(24 * 24 * 32, outputs)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resize the image to fit neural network, change order of channels to fit the expected PyTorch input type, and send image to device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    #T.Resize(40, interpolation=Image.CUBIC),\n",
    "                    #T.Resize(40),\n",
    "                    T.Resize(40),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "pos_blur_size = 10\n",
    "goal_blur_size = 10\n",
    "\n",
    "# create screen array, rows*columns*channels in size\n",
    "# channels are RGB\n",
    "screen = np.zeros((grid_shape[0], grid_shape[1], 3), dtype=np.uint8)\n",
    "def get_screen(new_episode=False, points=None):\n",
    "    global screen\n",
    "    state = env._get_obs()\n",
    "    last_pos = state[:2]\n",
    "    drone_pos = state[2:4]\n",
    "    goal_pos = state[4:]\n",
    "    if new_episode:\n",
    "        screen[:, :, 0] = env._heightmap\n",
    "        screen[:, :, 1:] = np.zeros((grid_shape[0], grid_shape[1], 2), dtype=np.uint8)\n",
    "        \n",
    "        # Scale red channel to be approximately 0 to 255\n",
    "        max_value = np.amax(env._heightmap)\n",
    "        min_value = np.amin(env._heightmap)\n",
    "        \n",
    "        # output[:, :, 0] /= max_value\n",
    "        # output[:, :, 0] *= 255\n",
    "\n",
    "        # Linear scale, in which every number is moved down\n",
    "        # by the lowest, so that lowest point lies at 0, and\n",
    "        # every point is linearly scaled by the factor needed\n",
    "        # to move the moved highest point to 255. The result is\n",
    "        # lowest point is at 0 and highest is at 255, and every\n",
    "        # other is somewhere inbetween\n",
    "        def scale_linear(highest, lowest, number):\n",
    "            return (number - lowest) * (255/(highest - lowest))\n",
    "\n",
    "        for y, row in enumerate(screen[:, :, 0]):\n",
    "            for x, cell in enumerate(row):\n",
    "                screen[y, x, 0] = scale_linear(max_value, min_value, cell)\n",
    "\n",
    "        blur_position(goal_pos, goal_blur_size, screen[:, :, 2])\n",
    "        #screen[:, :, 2] = screen[:, :, 1]\n",
    "    \n",
    "    # make copy of screen, by value, to modify for current frame\n",
    "    current_screen = screen[:, :, :]\n",
    "    if last_pos != (None, None):\n",
    "        blur_position(last_pos, pos_blur_size, current_screen[:, :, 1])\n",
    "    \n",
    "    blur_position(drone_pos, pos_blur_size, current_screen[:, :, 1])\n",
    "    blur_position(drone_pos, pos_blur_size, current_screen[:, :, 2])\n",
    "    if points is not None:\n",
    "        current_screen[:, :, 1] = np.zeros((grid_shape[0], grid_shape[1]), dtype=np.uint8)\n",
    "        for point in points:\n",
    "            current_screen[point[0], point[1]] = 255\n",
    "        pass\n",
    "    \n",
    "    output = current_screen.transpose((2, 0, 1))\n",
    "    _, screen_height, screen_width = output.shape\n",
    "    output = np.ascontiguousarray(current_screen, dtype=np.float32) / 255\n",
    "    output = torch.from_numpy(output)\n",
    "    output = output.type(torch.FloatTensor)\n",
    "    return resize(current_screen).unsqueeze(0).to(device)\n",
    "\n",
    "def lattice_distance(a, b):\n",
    "    a_x, a_y = a\n",
    "    b_x, b_y = b\n",
    "    return abs(a_x - b_x) + abs(a_y - b_y)\n",
    "\n",
    "def blur_position(position, blur_radius, table):\n",
    "    size_x, size_y = table.shape\n",
    "    for d_x in range(blur_radius * 2 + 1):\n",
    "        d_x -= blur_radius\n",
    "        for d_y in range(blur_radius * 2 + 1):\n",
    "            d_y -= blur_radius\n",
    "            # If the distance to the point is greater than the\n",
    "            # distance to be blurred, skip this cell.\n",
    "            distance = abs(d_x) + abs(d_y)\n",
    "            if distance > blur_radius:\n",
    "                continue\n",
    "            x, y = position\n",
    "            x += d_x\n",
    "            y += d_y\n",
    "            # Check if index is inside grid\n",
    "            if x < 0 or x >= size_x or y < 0 or y >= size_y:\n",
    "                continue\n",
    "            table[x][y] += 255 / (distance + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, 13, 37, 2, 17)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.imshow(np.swapaxes(np.swapaxes(np.squeeze(np.asarray(get_screen(True).cpu()), 0), 0, 2), 0, 1))\n",
    "reward = 0\n",
    "env.reset()\n",
    "#while reward == 0:\n",
    "#    env.reset()\n",
    "#    state_tuple, reward, done, info = env.step(99)\n",
    "#    get_screen(True)\n",
    "#    if not done:\n",
    "#        state_tuple, reward, done, info = env.step(random.randint(0, 100))\n",
    "print(env._get_obs())\n",
    "test = get_screen(True)\n",
    "plt.imshow(np.swapaxes(np.swapaxes(np.squeeze(np.asarray(test.cpu()), 0), 0, 2), 0, 1))\n",
    "#plt.imshow(np.swapaxes(np.squeeze(np.asarray(test.cpu()), 0), 0, 2))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.step(1)\n",
    "#plt.imshow(env.render(mode='rgb_array'))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.9\n",
    "#GAMMA = 0.1\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.01\n",
    "#EPS_END = 0.0\n",
    "EPS_DECAY = 35000\n",
    "TARGET_UPDATE = 10\n",
    "\n",
    "# Get screen size so that we can initialize layers correctly based on shape\n",
    "# returned from AI gym. Typical dimensions at this point are close to 3x40x90\n",
    "# which is the result of a clamped and down-scaled render buffer in get_screen()\n",
    "#init_screen = env.render(mode='rgb_array')\n",
    "#screen_height, screen_width, _ = init_screen.shape\n",
    "screen_height, screen_width = grid_shape\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "policy_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "# Reset these whenever \n",
    "episode_durations = []\n",
    "episode_rewards = []\n",
    "episode_best_reward = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_done = 0\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            state = get_screen()\n",
    "            policy_net.eval()\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_durations = []\n",
    "episode_rewards = []\n",
    "episode_best_reward = []\n",
    "def plot_durations():\n",
    "    # Plot episode durations\n",
    "    ax[0][0].cla()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    ax[0][0].set_xlabel('Episode')\n",
    "    ax[0][0].set_ylabel('Duration')\n",
    "    ax[0][0].plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        ax[0][0].plot(means.numpy())\n",
    "        \n",
    "    # Plot episode rewards\n",
    "    ax[0][1].cla()\n",
    "    rewards_t = torch.tensor(episode_rewards, dtype=torch.float)\n",
    "    best_rewards_t = torch.tensor(episode_best_reward, dtype=torch.float)\n",
    "    ax[0][1].set_xlabel('Episode')\n",
    "    ax[0][1].set_ylabel('Reward')\n",
    "    ax[0][1].plot(rewards_t.numpy())\n",
    "    ax[0][1].plot(best_rewards_t.numpy())\n",
    "    if len(rewards_t) >= 100:\n",
    "        means = rewards_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        ax[0][1].plot(means.numpy())\n",
    "    \n",
    "    # Plot environment\n",
    "    env.render()\n",
    "\n",
    "    # Plot environment as seen by the agent\n",
    "    ax[1][1].imshow(np.swapaxes(np.swapaxes(np.squeeze(np.asarray(get_screen().cpu()), 0), 0, 2), 0, 1))\n",
    "    ax[1][1].axis('off')\n",
    "    \n",
    "    # pause a bit so that plots are updated\n",
    "    plt.pause(0.001)\n",
    "    if is_ipython:\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                            batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                       if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    loss = F.smooth_l1_loss(state_action_values,\n",
    "                            expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reward Function:\n",
    "===\n",
    "Reward 1 for correct direction, -2 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-42a78244692c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mepisode_rewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi_episode\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0mplot_durations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-a675f32989f8>\u001b[0m in \u001b[0;36mplot_durations\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_ipython\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</opt/conda/lib/python3.7/site-packages/decorator.py:decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2103\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2104\u001b[0m                     \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2105\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2106\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2107\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    512\u001b[0m         }\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpil_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    391\u001b[0m              (self.toolbar._wait_cursor_for_draw_cm() if self.toolbar\n\u001b[1;32m    392\u001b[0m               else nullcontext()):\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;31m# don't forget to call the superclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1736\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2628\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2630\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             im, l, b, trans = self.make_image(\n\u001b[0;32m--> 626\u001b[0;31m                 renderer, renderer.get_image_magnification())\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mmake_image\u001b[0;34m(self, renderer, magnification, unsampled)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_bbox\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             magnification, unsampled=unsampled)\n\u001b[0m\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_unsampled_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_make_image\u001b[0;34m(self, A, in_bbox, out_bbox, clip_bbox, magnification, unsampled, round_to_pixel_border)\u001b[0m\n\u001b[1;32m    522\u001b[0m                     self, A[..., 3], out_shape, t, alpha=alpha)\n\u001b[1;32m    523\u001b[0m                 output = _resample(  # resample rgb channels\n\u001b[0;32m--> 524\u001b[0;31m                     self, _rgb_to_rgba(A[..., :3]), out_shape, t, alpha=alpha)\n\u001b[0m\u001b[1;32m    525\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_alpha\u001b[0m  \u001b[0;31m# recombine rgb and alpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_resample\u001b[0;34m(image_obj, data, out_shape, transform, resample, alpha)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0minterpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'hanning'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_shape\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 2D->2D, 3D->3D.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mresample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_episodes = 20000000\n",
    "#episode_durations = []\n",
    "#episode_rewards = []\n",
    "#episode_best_reward = []\n",
    "EPS_DECAY = 350000\n",
    "\n",
    "possible_start_points = [(5,5), (grid_shape[0] - 5, 5), (5, grid_shape[1] - 5), (grid_shape[0] - 5, grid_shape[1] - 5)]\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "    env.reset()\n",
    "    \n",
    "    current_screen = get_screen(True)\n",
    "    state = current_screen\n",
    "    total_reward = 0\n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        action = select_action(state)\n",
    "        state_tuple, reward, done, info = env.step(action.item())\n",
    "        last_x, last_y, drone_x, drone_y, goal_x, goal_y = state_tuple\n",
    "        last_point = (last_x, last_y)\n",
    "        drone_point = (drone_x, drone_y)\n",
    "        goal_point = (goal_x, goal_y)\n",
    "        \n",
    "        # Overwrite reward function\n",
    "        reward = torch.tensor([reward], device=device).type(torch.float)\n",
    "        \n",
    "        #print(env._points_traversed)\n",
    "        #print(info)\n",
    "        #print(state_tuple, reward, done, info)\n",
    "        \n",
    "        # Observe new state\n",
    "        last_screen = current_screen\n",
    "        if reward != 0:\n",
    "            reward /= len(info['points_traversed'])\n",
    "            #current_screen = get_screen(False, info['points_traversed'])\n",
    "            current_screen = get_screen(False)\n",
    "        #print(info)\n",
    "        \n",
    "        #next_state = current_screen\n",
    "        if not done:\n",
    "            next_state = current_screen\n",
    "            #pass\n",
    "        else:\n",
    "            next_state = None\n",
    "            #next_state = current_screen\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the target network)\n",
    "        optimize_model()\n",
    "        #if done or mistakes > 10:\n",
    "        if done:\n",
    "            #print(t + 1)\n",
    "            #episode_durations.append(t + 1) \n",
    "            episode_rewards.append(reward)\n",
    "            if i_episode % 200 == 0:\n",
    "                plot_durations()\n",
    "            break\n",
    "\n",
    "    # Update the target network, copying all weights and biases in DQN\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DQN Agent\n",
    "====\n",
    "Code taken from PyTorch DQN tutorial, then modified to work on our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_drone\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torch.onnx\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "#device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intialize environment along with the matplotlib figure.\n",
    "- DroneCardinal-v0 is the name of the environment to initialize\n",
    "- Rows and columns determine the shape of the environment area\n",
    "- Memory capacity says how many of the last steps shall be remembered and displayed when rendering with 'notebook' mode.\n",
    "- Ax takes a matplotlib plot, which it will plot to if given, otherwise plot to the default pyplot. This makes it so we can have the rendering of the playing as a matplotlib subplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 17, 19, 18])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x1008 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2)\n",
    "fig.set_figwidth(30)\n",
    "fig.set_figheight(14)\n",
    "\n",
    "grid_shape = (40, 40)\n",
    "#grid_shape = (105, 105)\n",
    "env = gym.make('DroneCardinal-v0',\n",
    "               rows=grid_shape[0],\n",
    "               columns=grid_shape[1],\n",
    "               memory_capacity=50,\n",
    "               ax=ax[1][0]).unwrapped\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import laps, redis, loader\n",
    "from Dijkstra.Dijkstra import *\n",
    "\n",
    "grid = env._grid\n",
    "\n",
    "grid = []\n",
    "width, height = grid_shape\n",
    "for x in range(width):\n",
    "    grid.append([])\n",
    "    for y in range(height):\n",
    "        grid[x].append(Node(env._grid[x, y], (x, y)))\n",
    "\n",
    "edges = get_edges(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the ReplayMemory object type. \n",
    "\n",
    "It is how transitions in the environment is stored, and randomly given back with the sample function, to train the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network\n",
    "=======\n",
    "The network is a convolutional neural network, which uses ReLu activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, h, w, outputs):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        #self.conv2 = nn.Conv2d(16, 32, kernel_size=4, stride=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Number of Linear input connections depends on output of conv2d layers\n",
    "        # and therefore the input image size, so compute it.\n",
    "        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        linear_input_size = convw * convh * 32\n",
    "        self.head = nn.Linear(linear_input_size, outputs)\n",
    "        #self.head = nn.Linear(24 * 24 * 32, outputs)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resize the image to fit neural network, change order of channels to fit the expected PyTorch input type, and send image to device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur_position(grid, position, blur_radius):\n",
    "    size_x, size_y = grid.shape\n",
    "    for d_x in range(blur_radius * 2 + 1):\n",
    "        d_x -= blur_radius\n",
    "        for d_y in range(blur_radius * 2 + 1):\n",
    "            d_y -= blur_radius\n",
    "            # If the distance to the point is greater than the\n",
    "            # distance to be blurred, skip this cell.\n",
    "            distance = abs(d_x) + abs(d_y)\n",
    "            if distance > blur_radius:\n",
    "                continue\n",
    "            x, y = position\n",
    "            x += d_x\n",
    "            y += d_y\n",
    "            # Check if index is inside grid\n",
    "            if x < 0 or x >= size_x or y < 0 or y >= size_y:\n",
    "                continue\n",
    "            grid[x, y] = 1 / (distance + 1)\n",
    "\n",
    "blur_radius = 10\n",
    "blur_arrays = np.zeros((grid_shape[0], grid_shape[1], grid_shape[0], grid_shape[1]))\n",
    "for y, array_row in enumerate(blur_arrays):\n",
    "    for x, array in enumerate(array_row):\n",
    "        blur_position(blur_arrays[y][x], (y, x), blur_radius)\n",
    "\n",
    "blur_tensors = torch.tensor(blur_arrays, dtype=torch.float64, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    #T.Resize(40, interpolation=Image.CUBIC),\n",
    "                    T.Resize(40),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "screen = None\n",
    "white_channel = np.zeros(grid_shape)\n",
    "def get_screen(new_episode=False):\n",
    "    global screen\n",
    "    drone_pos = tuple(env._get_obs()[:2])\n",
    "    goal_pos = tuple(env._get_obs()[2:])\n",
    "    \n",
    "    if new_episode:\n",
    "        screen = env.render(mode='rgb_array')\n",
    "        \n",
    "        # ignore heightmap\n",
    "        screen[:, :, 0] = white_channel\n",
    "        \n",
    "        screen = screen.transpose((2, 0, 1))\n",
    "        _, screen_height, screen_width = screen.shape\n",
    "        screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "        screen = torch.from_numpy(screen)\n",
    "        screen = screen.type(torch.FloatTensor)\n",
    "        screen = resize(screen).unsqueeze(0).to(device)\n",
    "    \n",
    "    # blur drone position\n",
    "    screen[0][1] = blur_tensors[drone_pos[0], drone_pos[1]]\n",
    "    # blur goal position\n",
    "    screen[0][2] = blur_tensors[goal_pos[0], goal_pos[1]]\n",
    "    \n",
    "    return screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.imshow(np.swapaxes(np.swapaxes(np.squeeze(np.asarray(get_screen(True).cpu()), 0), 0, 2), 0, 1))\n",
    "test = get_screen(True)\n",
    "plt.imshow(np.swapaxes(np.swapaxes(np.squeeze(np.asarray(test.cpu()), 0), 0, 2), 0, 1))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD6CAYAAABnLjEDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAO9klEQVR4nO3df8idZ33H8c9nWWvdFGqwC6Hp1s6VSZGZQVeU+UcX15GVQSpIscORQSEOVlAmw8x/1DGhA7X7Y8NRMWsGzrZUXcvofoQsoMKIjTXWtNE1dhUT0jwTDbbIMtJ+98d9JTs+PffznPvcv677XO8XhOec+zn3976uNN+ec77nOtfXESEAq+9nxh4AgGGQ7EAhSHagECQ7UAiSHSgEyQ4UolWy295t+zu2T9ne39WgAHTPy37ObnuLpP+UdJuk05KekHRXRDyzwTkLX8xNxtLD+U1itD2/7rFDzqGvMTCHYcdwXtJPIuY+/GcbjGG9WySdiojnJMn2g5L2SKpN9nm2NDhe99h5kxgybpNr1f2FM99h59vFuHKMe3/N46R2L+OvlfT9mfun0zEAGWrzzL4Q2/sk7ev7OgA21ibZz0i6bub+jnTsp0TE/UqvLpq8ZwfQrTbJ/oSkG23foCrJ3yPp9zc7af17jCm9H2p6rbbvNZlv8zEsGncVakXzjm9UyFs62SPiou17JP1ruuaBiHh62XgA+tXqPXtEPC7p8Y7GAqBHrKADCkGyA4Ug2YFC9P45+yxr8Wp8jpXOumO5rhLrK+4qzDfXTwmaxl0fY6NqPM/sQCFIdqAQJDtQCJIdKMSgBTrp1YWGnIsffSy9ZL71j12FJb85LCWuwzM7UAiSHSgEyQ4UgmQHCkGyA4UYfLns+gvmUOnsa+nl2OPqK26u42oSN9dPCepidLF5Bc/sQCFIdqAQJDtQiFbv2W0/L+lFSS9LuhgRN3cxKADd66JA91sR8YNFHtjk++xTKqrkOq6+4uY6riZxcygc9jXfOryMBwrRNtlD0r/Z/nrq/AIgU21fxr8jIs7Y/gVJh2x/OyK+PPuA2fZPTTpZAuhWq2f2iDiTfq5J+pKqzq7rH3N/RNwcETfzngEYz9L5Z/vnbb/+0m1JvyPpRFcDA9CtNi/jt0n6ku1Lcf4hIv5ls5OmvrtsruNivs3iTmkJbJO4ffV6e07SW5c9H8CweBsNFIJkBwpBsgOFGL39U85LL3Mt9jDffHeXHXu+fJ8dAMkOlIJkBwpBsgOFINmBQrC7bM35TcYw9hJJSdoSNXHnlGdXYr4t405pCWzTuHV4ZgcKQbIDhSDZgUKQ7EAhBi3QSePvLptrsad13Jp1kis735Zxcx1X27gslwVAsgOlINmBQpDsQCE2LdDZPiDp9yStRcRb0rGtkh6SdL2k5yXdGRE/2jSWhttwMtdiD/PNI26u42obt22B7gFJu9cd2y/pcETcKOlwug8gY5sme+rw8sN1h/dIOphuH5R0R8fjAtCxZT9n3xYRZ9PtF1TtIT/XbPunJov2AXSrdYEuIkJVg8e6319u/0SyA+NZNtnP2d4uSennWndDAtCHZV/GPyZpr6R7089HFzmpr91lx66grsKS3yZxc/2UoEncXMfVNm6rarztz0v6D0m/avu07btVJflttp+V9NvpPoCMbfrMHhF31fzqnR2PBUCPWEEHFIJkBwox+PfZ22w4OXbxo+m1prQEtkncXAuHdcdzHRcbTgLoBckOFIJkBwpBsgOFINmBQgze/mmozSumtrtsafMd++9xFT4VmReD3WUBkOxAKUh2oBAkO1CI0Qt0ORc/+lh6Wdp8c11KPLVC6SDfZwewGkh2oBAkO1AIkh0oxCJ70B2wvWb7xMyxj9o+Y/t4+nN7v8ME0NYi1fgHJP21pL9fd/y+iPhE2wvmUOnsa+nl2OPqK+7YS0KbjmHsTy+axh1t84qa9k8AJqbNe/Z7bD+VXua/obMRAejFssn+aUlvkrRT0llJn6x7oO19to/ZPnZxyYsBaG+pZI+IcxHxckS8Iukzkm7Z4LGXe70NvrslgMuWyj/b22e6uL5L0omNHn/5PC3+ffYpFVVyHVdfccdeEtpF3BwKpX3Md6Plspsme2r/dKukN9o+Lekjkm61vVNV99bnJb1vszgAxrVs+6fP9jAWAD1iBR1QCJIdKATJDhRi9M0rcl0SWnc813FNbanp2POd2hJYdpcFsDCSHSgEyQ4UgmQHCjH4cvUp7S6ba7GnWdyYc2x+Gaek3XSntAS2adw6PLMDhSDZgUKQ7EAhSHagECQ7UIjBl8vmuLtsrpXdbuK+uvLObrrTWgLbJC7LZQGQ7EApSHagEIu0f7rO9hHbz9h+2vb70/Gttg/Zfjb9ZO94IGOLFOguSvpgRDxp+/WSvm77kKQ/lHQ4Iu61vV/Sfkkf2ihQDrvL5lrsmVLcXMfVJG6u4+oibp1F2j+djYgn0+0XJZ2UdK2kPZIOpocdlHRHg+sCGFij9+y2r5f065KOSto2s3f8C5K2dToyAJ1a+HN226+T9AVJH4iIH9v//4leRITtV3+9qjpvn6R9kvSadmMF0MJCz+y2r1CV6J+LiC+mw+dsb0+/3y5pbd65s+2fruxixACWskhHGKtqCnEyIj4186vHJO2VdG/6+egiFxxqw8lciz1TWo3Vxfm5zjfXcbWN26r9k6TflPQHkr5l+3g69mFVSf6w7bslfU/SnQvEAjCSRdo/fVX1/8N4Z7fDAdAXVtABhSDZgUKQ7EAhRm//lOsS2CZxc/2UoGnckuab67jaxuX77ABIdqAUJDtQCJIdKMSkNpwcu/jR9FpjFw7rjjPfPMbVV9w6PLMDhSDZgUKQ7EAhSHagECQ7UIhBq/HScJtXsLtsfQzmuxqfAs07znJZACQ7UAqSHShEm/ZPH7V9xvbx9Of2/ocLYFlt2j9J0n0R8YlFL9bX99nHLqrkUDhkvs3GsAqF4XlxW+0um7q+nE23X7R9qf0TgAlp0/5Jku6x/ZTtA3RxBfK2cLKvb/8k6dOS3iRpp6pn/k/WnLfP9jHbxy50MGAAy1m6/VNEnIuIlyPiFUmfkXTLvHNn2z/R6w0YzyLV+Lntny71eUveJelE98MD0JU27Z/usr1TUkh6XtL7NgvUdvOKsSudTc8fe0loX3FXYb6r8CnQRjHmadP+6fEG1wEwMlbQAYUg2YFCkOxAIbL9PnuuxY8pLQntK+4qzHcVCsPzjvN9dgAkO1AKkh0oBMkOFIJkBwoxeK83dpedj/mu9pLfof4eqcYDINmBUpDsQCFIdqAQoxfoci5+9LH0kvnWP3YVlvzmsJS4Ds/sQCFIdqAQJDtQiEU2nLzK9tdsfzO1f/pYOn6D7aO2T9l+yPaV/Q8XwLIWKdBdkLQrIl5KW0p/1fY/S/oTVe2fHrT9t5LuVrWXfKML5lD86Gs11tjj6ituruNqEjfXwmFdjEG+zx6Vl9LdK9KfkLRL0iPp+EFJd2wWC8B4Fm0SsSVtI70m6ZCk70o6HxEX00NOi/5vQNYWSvbU+WWnpB2qOr+8edELzLZ/+p8lBwmgvUbV+Ig4L+mIpLdLutr2pbcXOySdqTnncvunq1oNFUAbi1Tjr7F9dbr9Wkm3STqpKunfnR62V9KjfQ0SQHuLVOO3Szpoe4uq/zk8HBH/ZPsZSQ/a/gtJ31DVD25DTb7PPqUKaq7j6ituruNqEjeHTwn6mO9G1fhF2j89paon+/rjz6mmcyuA/LCCDigEyQ4UgmQHCjH699mntvQy13Ex32Zxp7QEtmncOjyzA4Ug2YFCkOxAIUh2oBAkO1CIQavx0rR2l821sst8891dduz50v4JAMkOlIJkBwpBsgOFGHy5bI67y+Za7GG+/cWd2hLYQXaXBbAaSHagECQ7UIg27Z8esP1fto+nPzv7Hy6AZbVp/yRJfxoRj2xwLoBMLLLhZEia1/6psRx2l821sst8891ddmrzrbNU+6eIOJp+9XHbT9m+z/ZrGlwXwMCWav9k+y2S/kxVG6jfkLRV0ofmnTvb/uknHQ0aQHPLtn/aHRFnU4fXC5L+TjV7yM+2f/q59uMFsKRl2z992/b2dMyq2jWf6HOgANpp0/7p321fo6rudlzSHy1ywaF2l8212MN884ib67jaxu2r/dOuzc4FkA9W0AGFINmBQpDsQCFIdqAQo/d6y3VJaJO4q7AEtkncXD8laBI313G1jcvmFQBIdqAUJDtQCJIdKMSkdpcdu/jR9FpTWgLbJG6uhcO647mOq6+4dXhmBwpBsgOFINmBQpDsQCFIdqAQg1bjpeE2r5jabqulzXfsv8dV+FRkXgyWywIg2YFSkOxAIUh2oBCuujsNdDH7vyV9L919o6QfDHbx4TCv6Vmluf1SRFwz7xeDJvtPXdg+FhE3j3LxHjGv6Vnluc3iZTxQCJIdKMSYyX7/iNfuE/OanlWe22WjvWcHMCxexgOFGDzZbe+2/R3bp2zvH/r6XbJ9wPaa7RMzx7baPmT72fTzDWOOcRm2r7N9xPYztp+2/f50fNJzs32V7a/Z/maa18fS8RtsH03/Jh+yfeXYY+3DoMmeOsH+jaTflXSTpLts3zTkGDr2gKTd647tl3Q4Im6UdDjdn5qLkj4YETdJepukP07/naY+twuSdkXEWyXtlLTb9tsk/aWk+yLiVyT9SNLdI46xN0M/s98i6VREPBcR/yvpQUl7Bh5DZyLiy5J+uO7wHkkH0+2DqnrXT0pEnI2IJ9PtFyWdlHStJj63qLyU7l6R/oSkXZIeSccnN69FDZ3s10r6/sz90+nYKtkWEWfT7RckbRtzMG3Zvl5Vy+6jWoG52d5i+7ikNUmHJH1X0vmIuJgesor/JiVRoOtVVB91TPbjDtuvk/QFSR+IiB/P/m6qc4uIlyNip6Qdql5pvnnkIQ1m6GQ/I+m6mfs70rFVcs72dklKP9dGHs9SbF+hKtE/FxFfTIdXYm6SFBHnJR2R9HZJV9u+tA/EKv6blDR8sj8h6cZU/bxS0nskPTbwGPr2mKS96fZeSY+OOJal2Lakz0o6GRGfmvnVpOdm+xrbV6fbr5V0m6p6xBFJ704Pm9y8FjX4ohrbt0v6K1U77RyIiI8POoAO2f68pFtVfWvqnKSPSPpHSQ9L+kVV3/C7MyLWF/GyZvsdkr4i6VuSXkmHP6zqfftk52b711QV4LaoeqJ7OCL+3PYvqyoWb5X0DUnvjYgL4420H6ygAwpBgQ4oBMkOFIJkBwpBsgOFINmBQpDsQCFIdqAQJDtQiP8DjrxGduBBSkIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(env.render(mode='rgb_array'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.9\n",
    "#GAMMA = 0.1\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.01\n",
    "#EPS_END = 0.0\n",
    "EPS_DECAY = 20 * 4000\n",
    "TARGET_UPDATE = 10\n",
    "\n",
    "# Get screen size so that we can initialize layers correctly based on shape\n",
    "# returned from AI gym. Typical dimensions at this point are close to 3x40x90\n",
    "# which is the result of a clamped and down-scaled render buffer in get_screen()\n",
    "init_screen = env.render(mode='rgb_array')\n",
    "screen_height, screen_width, _ = init_screen.shape\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "policy_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.RMSprop(policy_net.parameters(), momentum=0.9)\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "# Reset these whenever \n",
    "episode_durations = []\n",
    "episode_rewards = []\n",
    "episode_best_reward = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_done = 0\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            state = get_screen()\n",
    "            policy_net.eval()\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_durations = []\n",
    "episode_rewards = []\n",
    "episode_best_reward = []\n",
    "def plot_durations():\n",
    "    # Plot episode durations\n",
    "    ax[0][0].cla()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    ax[0][0].set_xlabel('Episode')\n",
    "    ax[0][0].set_ylabel('Duration')\n",
    "    ax[0][0].plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        ax[0][0].plot(means.numpy())\n",
    "        \n",
    "    # Plot episode rewards\n",
    "    ax[0][1].cla()\n",
    "    rewards_t = torch.tensor(episode_rewards, dtype=torch.float)\n",
    "    best_rewards_t = torch.tensor(episode_best_reward, dtype=torch.float)\n",
    "    ax[0][1].set_xlabel('Episode')\n",
    "    ax[0][1].set_ylabel('Reward')\n",
    "    ax[0][1].plot(rewards_t.numpy())\n",
    "    ax[0][1].plot(best_rewards_t.numpy())\n",
    "    if len(rewards_t) >= 100:\n",
    "        means = rewards_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        ax[0][1].plot(means.numpy())\n",
    "    \n",
    "    # Plot environment\n",
    "    env.render()\n",
    "\n",
    "    # Plot environment as seen by the agent\n",
    "    ax[1][1].imshow(np.swapaxes(np.swapaxes(np.squeeze(np.asarray(get_screen().cpu()), 0), 0, 2), 0, 1))\n",
    "    ax[1][1].axis('off')\n",
    "    \n",
    "    # pause a bit so that plots are updated\n",
    "    plt.pause(0.001)\n",
    "    if is_ipython:\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                            batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                       if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    loss = F.smooth_l1_loss(state_action_values,\n",
    "                            expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reward Function:\n",
    "===\n",
    "Reward 1 for correct direction, -2 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-d1e56418ae4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;31m# Only plot graphs every hundreth episode for performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi_episode\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0mplot_durations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-a675f32989f8>\u001b[0m in \u001b[0;36mplot_durations\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_ipython\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</opt/conda/lib/python3.7/site-packages/decorator.py:decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2103\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2104\u001b[0m                     \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2105\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2106\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2107\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    512\u001b[0m         }\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpil_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    391\u001b[0m              (self.toolbar._wait_cursor_for_draw_cm() if self.toolbar\n\u001b[1;32m    392\u001b[0m               else nullcontext()):\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;31m# don't forget to call the superclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1736\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2628\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2630\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             im, l, b, trans = self.make_image(\n\u001b[0;32m--> 626\u001b[0;31m                 renderer, renderer.get_image_magnification())\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mmake_image\u001b[0;34m(self, renderer, magnification, unsampled)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_bbox\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             magnification, unsampled=unsampled)\n\u001b[0m\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_unsampled_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_make_image\u001b[0;34m(self, A, in_bbox, out_bbox, clip_bbox, magnification, unsampled, round_to_pixel_border)\u001b[0m\n\u001b[1;32m    522\u001b[0m                     self, A[..., 3], out_shape, t, alpha=alpha)\n\u001b[1;32m    523\u001b[0m                 output = _resample(  # resample rgb channels\n\u001b[0;32m--> 524\u001b[0;31m                     self, _rgb_to_rgba(A[..., :3]), out_shape, t, alpha=alpha)\n\u001b[0m\u001b[1;32m    525\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_alpha\u001b[0m  \u001b[0;31m# recombine rgb and alpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_resample\u001b[0;34m(image_obj, data, out_shape, transform, resample, alpha)\u001b[0m\n\u001b[1;32m    200\u001b[0m                     \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mimage_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_filternorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m                     image_obj.get_filterrad())\n\u001b[0m\u001b[1;32m    203\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_episodes = 20000000\n",
    "episode_durations = []\n",
    "episode_rewards = []\n",
    "episode_best_reward = []\n",
    "\n",
    "def lattice_distance(a, b):\n",
    "    a_x, a_y = a\n",
    "    b_x, b_y = b\n",
    "    return abs(a_x - b_x) + abs(a_y - b_y)\n",
    "\n",
    "possible_start_points = [(5,5), (grid_shape[0] - 5, 5), (5, grid_shape[1] - 5), (grid_shape[0] - 5, grid_shape[1] - 5)]\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "    env.reset()\n",
    "    \n",
    "    #env._goal_pos = (5, 5)\n",
    "    env._goal_pos = random.choice(possible_start_points)\n",
    "    mistakes = 0\n",
    "    \n",
    "    current_screen = get_screen(True)\n",
    "    state = current_screen\n",
    "    total_reward = 0\n",
    "    highest_grid_value = np.amax(env._grid)\n",
    "\n",
    "    for t in count():\n",
    "        last_x, last_y, _, _ = env._get_obs()\n",
    "        \n",
    "        # Select and perform an action\n",
    "        action = select_action(state)\n",
    "        state_tuple, reward, done, _ = env.step(action.item())\n",
    "        drone_x, drone_y, goal_x, goal_y = state_tuple\n",
    "        drone_point = (drone_x, drone_y)\n",
    "        goal_point = (goal_x, goal_y)\n",
    "        \n",
    "        # Hijack reward calculation (temporary?)\n",
    "        if (drone_x, drone_y) == (goal_x, goal_y):\n",
    "            reward = np.float64(0)\n",
    "        else:\n",
    "            diff = abs(goal_x - drone_x) + abs(goal_y - drone_y)\n",
    "            last_diff = abs(goal_x - last_x) + abs(goal_y - last_y)\n",
    "            if (last_diff > diff):\n",
    "                reward = np.float64(1)\n",
    "            else:\n",
    "                reward = np.float64(0)\n",
    "        \n",
    "        \n",
    "        total_reward += reward\n",
    "        reward = torch.tensor([reward], device=device).type(torch.float)\n",
    "        \n",
    "        # End episode early\n",
    "        if t > 200 or lattice_distance(drone_point, goal_point) < 2:\n",
    "            done = True\n",
    "        if reward == 0:\n",
    "            mistakes += 1\n",
    "            if mistakes >= 10:\n",
    "                done = True\n",
    "        \n",
    "        # Observe new state\n",
    "        last_screen = current_screen\n",
    "        current_screen = get_screen()\n",
    "        if not done:\n",
    "            next_state = current_screen\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the target network)\n",
    "        optimize_model()\n",
    "        \n",
    "        # Append max reward possible for graphing\n",
    "        if t == 0:\n",
    "            episode_best_reward.append(abs(last_x - goal_x) + abs(last_y - goal_y))\n",
    "        if done:\n",
    "            # The amount of steps the episode took\n",
    "            episode_durations.append(t + 1)\n",
    "            # Total reward gained divided by maximum, to get value between 0 and 1 of performance\n",
    "            episode_rewards.append(max(total_reward - mistakes, 0) / episode_best_reward[-1])\n",
    "            episode_best_reward[-1] = 1\n",
    "            # Only plot graphs every hundreth episode for performance\n",
    "            if i_episode % 100 == 0:\n",
    "                plot_durations()\n",
    "            break\n",
    "\n",
    "    # Update the target network, copying all weights and biases in DQN\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for i in range(10000):\n",
    "    get_screen(True)\n",
    "end = time.time()\n",
    "print((end - start) / 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = get_edges(grid)\n",
    "get_cost(dijkstra(edges, (2,5), (0,0)))\n",
    "#path = get_path(dijkstra_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cost(dijkstra(edges, (2,0), (0,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = env.render(mode='rgb_array')\n",
    "print(env._get_obs())\n",
    "\n",
    "def blur_grid(rgb_array):\n",
    "    def lattice_distance(a, b):\n",
    "        a_x, a_y = a\n",
    "        b_x, b_y = b\n",
    "        return abs(a_x - b_x) + abs(a_y - b_y)\n",
    "    \n",
    "    red_channel = rgb_array[:,:,2]\n",
    "    goal = tuple(env._get_obs()[2:])\n",
    "    diagonal = env._grid.shape[0] + env._grid.shape[1] - 1\n",
    "    \n",
    "    for x, column in enumerate(red_channel):\n",
    "        for y, cell in enumerate(column):\n",
    "            distance = lattice_distance((x, y), goal)\n",
    "            red_channel[x][y] = (255 / diagonal) * (distance + 1)\n",
    "    rgb_array[:, :, 2] = red_channel\n",
    "    return rgb_array\n",
    "\n",
    "test = blur_grid(test)\n",
    "print(test[:, :, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

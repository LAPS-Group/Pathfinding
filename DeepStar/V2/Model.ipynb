{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, onnx, torch, torch, csv\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as utils\n",
    "\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepStart network definition\n",
    "\n",
    "DeepStar consists of two layer of max pooled convolutional neural networks that is then fed into two layers of normal neural networks.\n",
    "\n",
    "**Get Loss**: Currently we use a custom loss function that is just the difference between the expected and output. Times 10 to keep the learning rate acceptable.<br>\n",
    "**Get Optim**: Currentl we are using the Adadelta loss function.http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepStar(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepStar, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=16, stride=2, padding=3)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=8, stride=2, padding=2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=4, stride=1, padding=0)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        #self.conv_dropout = nn.Dropout2d()\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(256 * 12 * 12 + 4, 64)\n",
    "        self.fc2 = torch.nn.Linear(64 + 4, 2)\n",
    "        \n",
    "    def __name__(self):\n",
    "        return \"DeepStar\"\n",
    "    \n",
    "    def get_loss(self):\n",
    "        return lambda o ,t: torch.mean(abs(o - t)) * 10\n",
    "        #return torch.nn.MSELoss()\n",
    "        \n",
    "    def get_optim(self, rho, lr, weight_decay):\n",
    "        return optim.Adadelta(self.parameters(), rho=rho, lr=lr, weight_decay=weight_decay)\n",
    "        #return optim.SGD(self.parameters(), lr=0.01, momentum=0.9)\n",
    "        \n",
    "    def forward(self, img, points):\n",
    "        img = self.forward_conv(img)\n",
    "\n",
    "        l = img.view(-1, self.conv_out)\n",
    "        l = torch.cat((l, points), 1)\n",
    "\n",
    "        l = F.relu(self.fc1(l))\n",
    "        l = self.dropout1(l)\n",
    "        \n",
    "        l = F.relu(self.fc2(l))\n",
    "        l = self.dropout2(l)\n",
    "\n",
    "        return self.fc3(l)\n",
    "    \n",
    "    def forward_conv(self, img):\n",
    "        img = F.relu(self.conv1(img))\n",
    "        img = self.pool1(img)\n",
    "\n",
    "        img = F.relu(self.conv2(img))\n",
    "        img = self.pool2(img)\n",
    "        \n",
    "        img = F.relu(self.conv3(img))\n",
    "        img = self.pool3(img)\n",
    "        \n",
    "        img = F.relu(self.conv4(img))\n",
    "        img = self.pool4(img)\n",
    "        \n",
    "        img = F.relu(self.conv5(img))\n",
    "        img = self.pool5(img)\n",
    "        \n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader\n",
    "\n",
    "Because we use a custom dataset we have to have a custom data loader. Currently we only use one map and one csv file for all paths generated on that map. The map is a grayscale heightmap normalzied to between 0 and 1. The data is a list of start and stop points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathDataLoader(utils.Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.map = f'{data_dir}map.png'\n",
    "        self.data_path = f'{data_dir}data.csv'\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        self.data = pd.read_csv(self.data_path, encoding = \"UTF-8\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data[\"Start\"])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        with Image.open(self.map) as img:\n",
    "            sx, sy = self.to_tuple(self.data[\"Start\"][idx])\n",
    "            ex, ey = self.to_tuple(self.data[\"Stop\"][idx])\n",
    "            mx, my = self.to_tuple(self.data[\"Midpoint\"][idx])\n",
    "\n",
    "            img_tensor = self.to_tensor(img)\n",
    "\n",
    "            return img_tensor, torch.FloatTensor([sx / 256, sy / 256, ex / 256, ey / 256]), (mx / 256, my / 256)\n",
    "    \n",
    "    def to_tuple(self, t):\n",
    "        return tuple(map(int, t.replace('(','').replace(')', '').split(', '))) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

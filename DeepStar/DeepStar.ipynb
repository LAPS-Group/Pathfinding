{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepStar Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import time, onnx, loader, torch, torchvision\n",
    "import torch.utils.data as utils\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from Model import DeepStar, PathDataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conv1: 3, 64\n",
    "Conv2: 64, 32\n",
    "\n",
    "Dropout might be bad idea, longer train might be needed to test\n",
    "\n",
    "Test 1: Fail, platoued at 0.07 loss\n",
    "Added droput layer\n",
    "Conv1 output layers from 64 to 20\n",
    "Conv2 input layesr from 64 to 20\n",
    "Conv2 output layers from 32 to 10\n",
    "Fc1 outputs from 64 to 20\n",
    "Fc2 inputs from 64 to 20\n",
    "\n",
    "Test 2: Fail, platoued at 0.08 loss\n",
    "Added droput layer\n",
    "Conv1 output layers from 64 to 128\n",
    "Conv2 input layesr from 64 to 128\n",
    "Conv2 output layers from 32 to 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = True\n",
    "save = True\n",
    "save_name = \"deep_star_v3\"\n",
    "\n",
    "image_size = (256, 256)\n",
    "\n",
    "data_folder = \"data\"\n",
    "batch_size = 10\n",
    "n_epochs = 20000\n",
    "shuffle_data = True\n",
    "\n",
    "rho = 0.9\n",
    "lr = 1\n",
    "weight_decay = 0\n",
    "\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = DeepStar()\n",
    "\n",
    "if (load):\n",
    "    net.load_state_dict(torch.load(save_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Here we load both the training data and validation data into different loaders. There are methods for automatically separating out training and validation data from a set but we do it manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = PathDataLoader(f'{data_folder}/images/')\n",
    "train_loader = utils.DataLoader(train_data, batch_size=batch_size, shuffle=shuffle_data, num_workers=4)\n",
    "\n",
    "val_data = PathDataLoader(f'{data_folder}/validation/')\n",
    "val_loader = utils.DataLoader(train_data, batch_size=batch_size, shuffle=shuffle_data, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure output for Tensor Board\n",
    "\n",
    "Here we write to special files that enable Tensor Board to visualize it. To open Tensor Board select the data/images/ folder and click the Tensorboard button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writer = SummaryWriter(f'{data_folder}/images')\n",
    "\n",
    "#dataiter = iter(train_loader)\n",
    "#images, labels = dataiter.next()\n",
    "\n",
    "#img_grid = torchvision.utils.make_grid(images)\n",
    "#writer.add_image('dataset', img_grid)\n",
    "\n",
    "#writer.add_graph(net, images)\n",
    "#writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 2523 batches\n",
      "Epoch 1, 10% \t train_loss: 0.274 took: 77.78s\n",
      "Epoch 1, 20% \t train_loss: 0.274 took: 76.63s\n",
      "Epoch 1, 30% \t train_loss: 0.272 took: 75.46s\n",
      "Epoch 1, 40% \t train_loss: 0.273 took: 76.46s\n",
      "Epoch 1, 50% \t train_loss: 0.275 took: 77.20s\n",
      "Epoch 1, 60% \t train_loss: 0.267 took: 78.02s\n",
      "Epoch 1, 70% \t train_loss: 0.272 took: 78.09s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-31bce73f15ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mloss_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_expected_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mloss_size\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_batches = len(train_loader)\n",
    "\n",
    "loss = net.get_loss()\n",
    "optimizer = net.get_optim(rho, lr, weight_decay)\n",
    "training_start_time = time.time()\n",
    "\n",
    "print(f'Training with {n_batches} batches')\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    print_every = n_batches // 10\n",
    "    start_time = time.time()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inp, e = data\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        new_expected_tensor = []\n",
    "        for a in range(len(e[0])):\n",
    "            new_expected_tensor.append([\n",
    "                e[0][a].item(),\n",
    "                e[1][a].item()])\n",
    "        \n",
    "        new_expected_tensor = torch.tensor(new_expected_tensor)\n",
    "        \n",
    "        output = net(inp)\n",
    "        loss_size = loss(output, new_expected_tensor)\n",
    "        loss_size.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss_size.data.item()\n",
    "        total_train_loss += loss_size.data.item()\n",
    "\n",
    "        if (i + 1) % (print_every + 1) == 0:\n",
    "            print(\"Epoch {}, {:d}% \\t train_loss: {:.3f} took: {:.2f}s\".format(epoch+1, int(100 * (i+1) / n_batches), running_loss / print_every, time.time() - start_time))\n",
    "\n",
    "            running_loss = 0.0\n",
    "            start_time = time.time()\n",
    "            \n",
    "        total_val_loss = 0\n",
    "    for inp, e in val_loader:\n",
    "        new_expected_tensor = []\n",
    "        for a in range(len(e[0])):\n",
    "            new_expected_tensor.append([\n",
    "                e[0][a].item(),\n",
    "                e[1][a].item()])\n",
    "        \n",
    "        new_expected_tensor = torch.tensor(new_expected_tensor)\n",
    "        \n",
    "        val_outputs = net(inp)\n",
    "        val_loss_size = loss(val_outputs, new_expected_tensor)\n",
    "        total_val_loss += val_loss_size.data.item()\n",
    "\n",
    "    print(\"Validation loss = {:.3f}\".format(total_val_loss / len(val_loader)))\n",
    "\n",
    "print(\"Training finished, took {:.2f}s\".format(time.time() - training_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (save):\n",
    "    torch.save(net.state_dict(), f'{save_name}')\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "\n",
    "point = (184, 170)\n",
    "img = Image.open(\"data/{0}_{1}_confirm.png\".format(point[0], point[1]))\n",
    "to_tensor = transforms.ToTensor()\n",
    "img_tensor = to_tensor(img).unsqueeze(0)\n",
    "\n",
    "output = net(img_tensor)\n",
    "print(output)\n",
    "print(round(output[0][0].item() * 256), round(output[0][1].item() * 256))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

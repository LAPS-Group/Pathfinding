{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, torch, torch, csv\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as utils\n",
    "\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepStart network definition\n",
    "\n",
    "DeepStar consists of two layer of max pooled convolutional neural networks that is then fed into two layers of normal neural networks.\n",
    "\n",
    "**Get Optim**: Currentyl we are using the SGD optimizer function.<br>\n",
    "**Get Loss**: Currentl we are using the Csross Entry Loss<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepStar(nn.Module):\n",
    "    def __init__(self, prediction_size):\n",
    "        super(DeepStar, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=4, stride=2, padding=0)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(256, 512, kernel_size=1, stride=2, padding=0)\n",
    "        self.pool5 = nn.MaxPool2d(kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        #self.conv_dropout = nn.Dropout2d()\n",
    "        self.conv_out = 512 * 9 * 9\n",
    "        px, py = prediction_size\n",
    "\n",
    "        self.fc1 = nn.Linear(self.conv_out + 4, px*py*2)\n",
    "        self.dropout1 = nn.Dropout(p=0.25)\n",
    "        self.fc2 = nn.Linear(px*py*2, px*py + 1)\n",
    "        \n",
    "    def __name__(self):\n",
    "        return \"DeepStar\"\n",
    "    \n",
    "    def get_loss(self):\n",
    "        return nn.CrossEntropyLoss()\n",
    "        \n",
    "    def get_optim(self, lr, momentum):\n",
    "        return optim.SGD(self.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "        \n",
    "    def forward(self, img, points):\n",
    "        img = self.forward_conv(img)\n",
    "\n",
    "        l = img.view(-1, self.conv_out)\n",
    "        l = torch.cat((l, points), 1)\n",
    "        \n",
    "        l = F.relu(self.fc1(l))\n",
    "        l = self.dropout1(l)\n",
    "\n",
    "        return self.fc2(l)\n",
    "    \n",
    "    def forward_conv(self, img):\n",
    "        img = F.relu(self.conv1(img))\n",
    "        img = self.pool1(img)\n",
    "\n",
    "        img = F.relu(self.conv2(img))\n",
    "        img = self.pool2(img)\n",
    "        \n",
    "        img = F.relu(self.conv3(img))\n",
    "        img = self.pool3(img)\n",
    "        \n",
    "        img = F.relu(self.conv4(img))\n",
    "        img = self.pool4(img)\n",
    "        \n",
    "        img = F.relu(self.conv5(img))\n",
    "        img = self.pool5(img)\n",
    "        \n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader\n",
    "\n",
    "Because we use a custom dataset we have to have a custom data loader. Currently we only use one map and one csv file for all paths generated on that map. The map is a grayscale heightmap normalzied to between 0 and 1. The data is a list of start and stop points. To make this netowrk a classifier we create a label for each point the midpoint can be in. So labels will be width*height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathDataLoader(utils.Dataset):\n",
    "    def __init__(self, data_dir, prediction_size):\n",
    "        self.map = f'{data_dir}/map.png'\n",
    "        self.data_path = f'{data_dir}/data.csv'\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        self.data = pd.read_csv(self.data_path, encoding = \"UTF-8\")\n",
    "        self.size = prediction_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data[\"Start\"])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        with Image.open(self.map) as img:\n",
    "            imgWidth, imgHeight = img.size\n",
    "            width, height = self.size\n",
    "\n",
    "            sx, sy = self.to_tuple(self.data[\"Start\"][idx])\n",
    "            ex, ey = self.to_tuple(self.data[\"Stop\"][idx])\n",
    "            mx, my = self.to_tuple(self.data[\"Midpoint\"][idx])\n",
    "            \n",
    "            label = round((mx / imgWidth) * width) + (width - 1) * round((my / imgHeight) * height)\n",
    "\n",
    "            img_tensor = self.to_tensor(img)\n",
    "            pos_tensor = torch.FloatTensor([sx / imgWidth, sy / imgHeight, ex / imgWidth, ey / imgHeight])\n",
    "            label_tensor = torch.LongTensor([label])\n",
    "            \n",
    "            #print(f'{img_tensor.size()}-{pos_tensor.size()}-{label_tensor.size()}')\n",
    "            \n",
    "            return img_tensor, pos_tensor, label_tensor\n",
    "    \n",
    "    def to_tuple(self, t):\n",
    "        return tuple(map(int, t.replace('(','').replace(')', '').split(', '))) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

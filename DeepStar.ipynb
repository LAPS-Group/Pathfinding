{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, glob, os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as utils\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepStar(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepStar, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = torch.nn.MaxPool2d(kernel_size=4, stride=4, padding=0)\n",
    "        \n",
    "        self.conv2 = torch.nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = torch.nn.MaxPool2d(kernel_size=4, stride=4, padding=0)\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(32 * 16 * 16, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = x.view(-1, 32 * 16 *16)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "net = DeepStar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathDataLoader(utils.Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.files = glob.glob(data_dir + \"*.png\")\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.files[idx]\n",
    "        \n",
    "        image_name = os.path.basename(file_path)\n",
    "        img_as_img = Image.open(file_path)\n",
    "        img_as_tensor = self.to_tensor(img_as_img)\n",
    "        \n",
    "        numbers = image_name.split(\"_\")\n",
    "        #print(len(numbers))\n",
    "        \n",
    "        x = float(numbers[0]) / 256.0\n",
    "        y = float(numbers[1]) / 256.0\n",
    "        \n",
    "        return (img_as_tensor, [x, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLossAndOptimizer(net, learning_rate=0.001):\n",
    "    loss = torch.nn.L1Loss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    \n",
    "    return(loss, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = PathDataLoader(\"data/heightmap/images/\")\n",
    "train_loader = utils.DataLoader(train_data, batch_size=5, shuffle=True, num_workers=4)\n",
    "\n",
    "val_data = PathDataLoader(\"data/heightmap/validation/\")\n",
    "val_loader = utils.DataLoader(train_data, batch_size=5, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 202 images\n",
      "Epoch 1, 10% \t train_loss: 0.27 took: 8.59s\n",
      "Epoch 1, 20% \t train_loss: 0.21 took: 8.35s\n",
      "Epoch 1, 31% \t train_loss: 0.22 took: 8.34s\n",
      "Epoch 1, 41% \t train_loss: 0.21 took: 8.80s\n",
      "Epoch 1, 51% \t train_loss: 0.21 took: 8.84s\n",
      "Epoch 1, 62% \t train_loss: 0.20 took: 8.53s\n",
      "Epoch 1, 72% \t train_loss: 0.18 took: 8.38s\n",
      "Epoch 1, 83% \t train_loss: 0.19 took: 7.75s\n",
      "Epoch 1, 93% \t train_loss: 0.18 took: 7.72s\n",
      "Validation loss = 0.18\n",
      "Epoch 2, 10% \t train_loss: 0.19 took: 8.20s\n",
      "Epoch 2, 20% \t train_loss: 0.20 took: 8.55s\n",
      "Epoch 2, 31% \t train_loss: 0.20 took: 8.79s\n",
      "Epoch 2, 41% \t train_loss: 0.19 took: 8.07s\n",
      "Epoch 2, 51% \t train_loss: 0.19 took: 8.50s\n",
      "Epoch 2, 62% \t train_loss: 0.22 took: 8.23s\n",
      "Epoch 2, 72% \t train_loss: 0.20 took: 8.00s\n",
      "Epoch 2, 83% \t train_loss: 0.19 took: 8.14s\n",
      "Epoch 2, 93% \t train_loss: 0.16 took: 8.08s\n",
      "Validation loss = 0.12\n",
      "Epoch 3, 10% \t train_loss: 0.12 took: 7.87s\n",
      "Epoch 3, 20% \t train_loss: 0.11 took: 8.07s\n",
      "Epoch 3, 31% \t train_loss: 0.10 took: 10.77s\n",
      "Epoch 3, 41% \t train_loss: 0.11 took: 8.25s\n",
      "Epoch 3, 51% \t train_loss: 0.10 took: 7.82s\n",
      "Epoch 3, 62% \t train_loss: 0.10 took: 9.04s\n",
      "Epoch 3, 72% \t train_loss: 0.10 took: 7.79s\n",
      "Epoch 3, 83% \t train_loss: 0.08 took: 8.34s\n",
      "Epoch 3, 93% \t train_loss: 0.08 took: 8.47s\n",
      "Validation loss = 0.05\n",
      "Epoch 4, 10% \t train_loss: 0.07 took: 8.87s\n",
      "Epoch 4, 20% \t train_loss: 0.07 took: 7.64s\n",
      "Epoch 4, 31% \t train_loss: 0.07 took: 7.83s\n",
      "Epoch 4, 41% \t train_loss: 0.07 took: 8.21s\n",
      "Epoch 4, 51% \t train_loss: 0.07 took: 8.32s\n",
      "Epoch 4, 62% \t train_loss: 0.06 took: 8.62s\n",
      "Epoch 4, 72% \t train_loss: 0.07 took: 8.36s\n",
      "Epoch 4, 83% \t train_loss: 0.07 took: 8.04s\n",
      "Epoch 4, 93% \t train_loss: 0.07 took: 8.35s\n",
      "Validation loss = 0.04\n",
      "Epoch 5, 10% \t train_loss: 0.06 took: 8.03s\n",
      "Epoch 5, 20% \t train_loss: 0.06 took: 7.77s\n",
      "Epoch 5, 31% \t train_loss: 0.06 took: 7.70s\n",
      "Epoch 5, 41% \t train_loss: 0.06 took: 7.58s\n",
      "Epoch 5, 51% \t train_loss: 0.07 took: 7.64s\n",
      "Epoch 5, 62% \t train_loss: 0.06 took: 7.59s\n",
      "Epoch 5, 72% \t train_loss: 0.06 took: 7.60s\n",
      "Epoch 5, 83% \t train_loss: 0.07 took: 7.62s\n",
      "Epoch 5, 93% \t train_loss: 0.06 took: 7.69s\n",
      "Validation loss = 0.05\n",
      "Epoch 6, 10% \t train_loss: 0.05 took: 7.91s\n",
      "Epoch 6, 20% \t train_loss: 0.06 took: 7.78s\n",
      "Epoch 6, 31% \t train_loss: 0.06 took: 7.76s\n",
      "Epoch 6, 41% \t train_loss: 0.06 took: 7.85s\n",
      "Epoch 6, 51% \t train_loss: 0.06 took: 8.44s\n",
      "Epoch 6, 62% \t train_loss: 0.05 took: 7.98s\n",
      "Epoch 6, 72% \t train_loss: 0.06 took: 7.89s\n",
      "Epoch 6, 83% \t train_loss: 0.06 took: 7.65s\n",
      "Epoch 6, 93% \t train_loss: 0.05 took: 7.95s\n",
      "Validation loss = 0.09\n",
      "Epoch 7, 10% \t train_loss: 0.05 took: 8.05s\n",
      "Epoch 7, 20% \t train_loss: 0.05 took: 7.79s\n",
      "Epoch 7, 31% \t train_loss: 0.05 took: 8.32s\n",
      "Epoch 7, 41% \t train_loss: 0.05 took: 7.97s\n",
      "Epoch 7, 51% \t train_loss: 0.05 took: 8.02s\n",
      "Epoch 7, 62% \t train_loss: 0.06 took: 7.86s\n",
      "Epoch 7, 72% \t train_loss: 0.05 took: 8.75s\n",
      "Epoch 7, 83% \t train_loss: 0.06 took: 8.92s\n",
      "Epoch 7, 93% \t train_loss: 0.06 took: 8.16s\n",
      "Validation loss = 0.06\n",
      "Epoch 8, 10% \t train_loss: 0.05 took: 8.28s\n",
      "Epoch 8, 20% \t train_loss: 0.05 took: 8.17s\n",
      "Epoch 8, 31% \t train_loss: 0.05 took: 7.96s\n",
      "Epoch 8, 41% \t train_loss: 0.05 took: 7.70s\n",
      "Epoch 8, 51% \t train_loss: 0.05 took: 7.85s\n",
      "Epoch 8, 62% \t train_loss: 0.06 took: 9.82s\n",
      "Epoch 8, 72% \t train_loss: 0.06 took: 8.46s\n",
      "Epoch 8, 83% \t train_loss: 0.05 took: 7.84s\n",
      "Epoch 8, 93% \t train_loss: 0.06 took: 7.69s\n",
      "Validation loss = 0.06\n",
      "Epoch 9, 10% \t train_loss: 0.05 took: 8.33s\n",
      "Epoch 9, 20% \t train_loss: 0.05 took: 8.32s\n",
      "Epoch 9, 31% \t train_loss: 0.04 took: 8.80s\n",
      "Epoch 9, 41% \t train_loss: 0.04 took: 9.10s\n",
      "Epoch 9, 51% \t train_loss: 0.05 took: 8.70s\n",
      "Epoch 9, 62% \t train_loss: 0.05 took: 7.98s\n",
      "Epoch 9, 72% \t train_loss: 0.05 took: 7.67s\n",
      "Epoch 9, 83% \t train_loss: 0.04 took: 7.71s\n",
      "Epoch 9, 93% \t train_loss: 0.04 took: 7.66s\n",
      "Validation loss = 0.04\n",
      "Epoch 10, 10% \t train_loss: 0.05 took: 8.56s\n",
      "Epoch 10, 20% \t train_loss: 0.05 took: 8.98s\n",
      "Epoch 10, 31% \t train_loss: 0.05 took: 8.57s\n",
      "Epoch 10, 41% \t train_loss: 0.04 took: 8.16s\n",
      "Epoch 10, 51% \t train_loss: 0.05 took: 9.01s\n",
      "Epoch 10, 62% \t train_loss: 0.04 took: 8.37s\n",
      "Epoch 10, 72% \t train_loss: 0.05 took: 7.95s\n",
      "Epoch 10, 83% \t train_loss: 0.05 took: 8.40s\n",
      "Epoch 10, 93% \t train_loss: 0.05 took: 7.73s\n",
      "Validation loss = 0.03\n",
      "Epoch 11, 10% \t train_loss: 0.04 took: 7.77s\n",
      "Epoch 11, 20% \t train_loss: 0.04 took: 7.59s\n",
      "Epoch 11, 31% \t train_loss: 0.05 took: 7.84s\n",
      "Epoch 11, 41% \t train_loss: 0.04 took: 8.09s\n",
      "Epoch 11, 51% \t train_loss: 0.05 took: 7.84s\n",
      "Epoch 11, 62% \t train_loss: 0.04 took: 8.16s\n",
      "Epoch 11, 72% \t train_loss: 0.04 took: 8.15s\n",
      "Epoch 11, 83% \t train_loss: 0.04 took: 8.87s\n",
      "Epoch 11, 93% \t train_loss: 0.04 took: 7.71s\n",
      "Validation loss = 0.06\n",
      "Epoch 12, 10% \t train_loss: 0.04 took: 7.89s\n",
      "Epoch 12, 20% \t train_loss: 0.05 took: 7.63s\n",
      "Epoch 12, 31% \t train_loss: 0.04 took: 7.63s\n",
      "Epoch 12, 41% \t train_loss: 0.04 took: 7.67s\n",
      "Epoch 12, 51% \t train_loss: 0.04 took: 7.55s\n",
      "Epoch 12, 62% \t train_loss: 0.04 took: 7.66s\n",
      "Epoch 12, 72% \t train_loss: 0.04 took: 8.24s\n",
      "Epoch 12, 83% \t train_loss: 0.05 took: 8.43s\n",
      "Epoch 12, 93% \t train_loss: 0.05 took: 7.71s\n",
      "Validation loss = 0.05\n",
      "Epoch 13, 10% \t train_loss: 0.04 took: 8.56s\n",
      "Epoch 13, 20% \t train_loss: 0.04 took: 8.67s\n",
      "Epoch 13, 31% \t train_loss: 0.04 took: 8.79s\n",
      "Epoch 13, 41% \t train_loss: 0.04 took: 8.74s\n",
      "Epoch 13, 51% \t train_loss: 0.04 took: 8.38s\n",
      "Epoch 13, 62% \t train_loss: 0.04 took: 8.85s\n",
      "Epoch 13, 72% \t train_loss: 0.04 took: 8.74s\n",
      "Epoch 13, 83% \t train_loss: 0.04 took: 8.21s\n",
      "Epoch 13, 93% \t train_loss: 0.04 took: 8.45s\n",
      "Validation loss = 0.03\n",
      "Epoch 14, 10% \t train_loss: 0.04 took: 7.82s\n",
      "Epoch 14, 20% \t train_loss: 0.04 took: 7.70s\n",
      "Epoch 14, 31% \t train_loss: 0.04 took: 7.64s\n",
      "Epoch 14, 41% \t train_loss: 0.04 took: 7.69s\n",
      "Epoch 14, 51% \t train_loss: 0.04 took: 7.62s\n",
      "Epoch 14, 62% \t train_loss: 0.04 took: 7.62s\n",
      "Epoch 14, 72% \t train_loss: 0.04 took: 7.65s\n",
      "Epoch 14, 83% \t train_loss: 0.04 took: 7.78s\n",
      "Epoch 14, 93% \t train_loss: 0.04 took: 8.12s\n",
      "Validation loss = 0.03\n",
      "Epoch 15, 10% \t train_loss: 0.04 took: 8.15s\n",
      "Epoch 15, 20% \t train_loss: 0.03 took: 9.08s\n",
      "Epoch 15, 31% \t train_loss: 0.04 took: 8.70s\n",
      "Epoch 15, 41% \t train_loss: 0.04 took: 8.14s\n",
      "Epoch 15, 51% \t train_loss: 0.04 took: 7.79s\n",
      "Epoch 15, 62% \t train_loss: 0.04 took: 7.72s\n",
      "Epoch 15, 72% \t train_loss: 0.04 took: 7.77s\n",
      "Epoch 15, 83% \t train_loss: 0.04 took: 7.70s\n",
      "Epoch 15, 93% \t train_loss: 0.04 took: 8.29s\n",
      "Validation loss = 0.04\n",
      "Epoch 16, 10% \t train_loss: 0.04 took: 9.00s\n",
      "Epoch 16, 20% \t train_loss: 0.04 took: 8.13s\n",
      "Epoch 16, 31% \t train_loss: 0.04 took: 8.59s\n",
      "Epoch 16, 41% \t train_loss: 0.04 took: 8.19s\n",
      "Epoch 16, 51% \t train_loss: 0.04 took: 8.08s\n",
      "Epoch 16, 62% \t train_loss: 0.04 took: 7.60s\n",
      "Epoch 16, 72% \t train_loss: 0.04 took: 8.01s\n",
      "Epoch 16, 83% \t train_loss: 0.04 took: 8.42s\n",
      "Epoch 16, 93% \t train_loss: 0.04 took: 8.09s\n",
      "Validation loss = 0.03\n",
      "Epoch 17, 10% \t train_loss: 0.04 took: 7.78s\n",
      "Epoch 17, 20% \t train_loss: 0.03 took: 7.75s\n",
      "Epoch 17, 31% \t train_loss: 0.04 took: 7.64s\n",
      "Epoch 17, 41% \t train_loss: 0.03 took: 8.29s\n",
      "Epoch 17, 51% \t train_loss: 0.04 took: 8.96s\n",
      "Epoch 17, 62% \t train_loss: 0.03 took: 8.33s\n",
      "Epoch 17, 72% \t train_loss: 0.03 took: 8.21s\n",
      "Epoch 17, 83% \t train_loss: 0.05 took: 8.64s\n",
      "Epoch 17, 93% \t train_loss: 0.04 took: 8.31s\n",
      "Validation loss = 0.03\n",
      "Epoch 18, 10% \t train_loss: 0.03 took: 8.93s\n",
      "Epoch 18, 20% \t train_loss: 0.04 took: 8.88s\n",
      "Epoch 18, 31% \t train_loss: 0.03 took: 8.73s\n",
      "Epoch 18, 41% \t train_loss: 0.04 took: 8.55s\n",
      "Epoch 18, 51% \t train_loss: 0.04 took: 7.71s\n",
      "Epoch 18, 62% \t train_loss: 0.04 took: 7.63s\n",
      "Epoch 18, 72% \t train_loss: 0.04 took: 7.68s\n",
      "Epoch 18, 83% \t train_loss: 0.04 took: 7.62s\n",
      "Epoch 18, 93% \t train_loss: 0.04 took: 7.75s\n",
      "Validation loss = 0.02\n",
      "Epoch 19, 10% \t train_loss: 0.03 took: 8.72s\n",
      "Epoch 19, 20% \t train_loss: 0.04 took: 8.23s\n",
      "Epoch 19, 31% \t train_loss: 0.04 took: 8.28s\n",
      "Epoch 19, 41% \t train_loss: 0.03 took: 8.61s\n",
      "Epoch 19, 51% \t train_loss: 0.03 took: 8.40s\n",
      "Epoch 19, 62% \t train_loss: 0.04 took: 7.65s\n",
      "Epoch 19, 72% \t train_loss: 0.04 took: 7.72s\n",
      "Epoch 19, 83% \t train_loss: 0.03 took: 7.60s\n",
      "Epoch 19, 93% \t train_loss: 0.04 took: 7.68s\n",
      "Validation loss = 0.05\n",
      "Epoch 20, 10% \t train_loss: 0.03 took: 9.52s\n",
      "Epoch 20, 20% \t train_loss: 0.04 took: 8.72s\n",
      "Epoch 20, 31% \t train_loss: 0.03 took: 7.59s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, 41% \t train_loss: 0.03 took: 7.73s\n",
      "Epoch 20, 51% \t train_loss: 0.04 took: 8.27s\n",
      "Epoch 20, 62% \t train_loss: 0.03 took: 7.92s\n",
      "Epoch 20, 72% \t train_loss: 0.04 took: 7.74s\n",
      "Epoch 20, 83% \t train_loss: 0.04 took: 9.22s\n",
      "Epoch 20, 93% \t train_loss: 0.04 took: 8.44s\n",
      "Validation loss = 0.03\n",
      "Training finished, took 2440.60s\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "n_epochs = 20\n",
    "learning_rate = 0.002\n",
    "\n",
    "n_batches = len(train_loader)\n",
    "\n",
    "loss, optimizer = createLossAndOptimizer(net, learning_rate)\n",
    "\n",
    "training_start_time = time.time()\n",
    "\n",
    "#Loop for n_epochs\n",
    "print(\"Training with {} images\".format(len(train_loader)))\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    print_every = n_batches // 10\n",
    "    start_time = time.time()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        img, pos = data\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        expected = torch.ones(len(img),2,requires_grad=False)\n",
    "        for a in range(len(img)):\n",
    "            expected[a][0] = pos[0][a]\n",
    "            expected[a][1] = pos[1][a]\n",
    "        \n",
    "        output = net(img)\n",
    "        loss_size = loss(output, expected)\n",
    "        loss_size.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss_size.data.item()\n",
    "        total_train_loss += loss_size.data.item()\n",
    "        \n",
    "        if (i + 1) % (print_every + 1) == 0:\n",
    "            print(\"Epoch {}, {:d}% \\t train_loss: {:.2f} took: {:.2f}s\".format(epoch+1, int(100 * (i+1) / n_batches), running_loss / print_every, time.time() - start_time))\n",
    "            #Reset running loss and time\n",
    "            running_loss = 0.0\n",
    "            start_time = time.time()\n",
    "            \n",
    "    total_val_loss = 0\n",
    "    for inputs, labels in val_loader:\n",
    "\n",
    "        #Wrap tensors in Variables\n",
    "        img, expected = Variable(img), Variable(expected)\n",
    "\n",
    "        #Forward pass\n",
    "        val_outputs = net(img)\n",
    "        val_loss_size = loss(val_outputs, expected)\n",
    "        total_val_loss += val_loss_size.data.item()\n",
    "\n",
    "    print(\"Validation loss = {:.2f}\".format(total_val_loss / len(val_loader)))\n",
    "\n",
    "print(\"Training finished, took {:.2f}s\".format(time.time() - training_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7987, 0.7604]], grad_fn=<AddmmBackward>)\n",
      "204 195\n"
     ]
    }
   ],
   "source": [
    "point = (207, 197)\n",
    "img = Image.open(\"data/{0}_{1}_confirm.png\".format(point[0], point[1]))\n",
    "to_tensor = transforms.ToTensor()\n",
    "img_tensor = to_tensor(img).unsqueeze(0)\n",
    "\n",
    "output = net(img_tensor)\n",
    "print(output)\n",
    "print(round(output[0][0].item() * 256), round(output[0][1].item() * 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = (34, 153)\n",
    "end = (231, 123)\n",
    "\n",
    "img = Image.open(\"data/map.png\").format(point[0], paint[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, glob, os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as utils\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepStar(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepStar, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = torch.nn.MaxPool2d(kernel_size=4, stride=4, padding=0)\n",
    "        \n",
    "        self.conv2 = torch.nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = torch.nn.MaxPool2d(kernel_size=4, stride=4, padding=0)\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(32 * 16 * 16, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = x.view(-1, 32 * 16 *16)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "net = DeepStar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathDataLoader(utils.Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.files = glob.glob(data_dir + \"*.png\")\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.files[idx]\n",
    "        \n",
    "        image_name = os.path.basename(file_path)\n",
    "        img_as_img = Image.open(file_path)\n",
    "        img_as_tensor = self.to_tensor(img_as_img)\n",
    "        \n",
    "        numbers = image_name.split(\"_\")\n",
    "        #print(len(numbers))\n",
    "        \n",
    "        x = float(numbers[0]) / 256.0\n",
    "        y = float(numbers[1]) / 256.0\n",
    "        \n",
    "        return (img_as_tensor, [x, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLossAndOptimizer(net, learning_rate=0.001):\n",
    "    loss = torch.nn.L1Loss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    \n",
    "    return(loss, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = PathDataLoader(\"data/heightmap/images/\")\n",
    "train_loader = utils.DataLoader(train_data, batch_size=5, shuffle=True, num_workers=4)\n",
    "\n",
    "val_data = PathDataLoader(\"data/heightmap/validation/\")\n",
    "val_loader = utils.DataLoader(train_data, batch_size=5, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 202 images\n",
      "Epoch 1, 10% \t train_loss: 0.27 took: 8.59s\n",
      "Epoch 1, 20% \t train_loss: 0.21 took: 8.35s\n",
      "Epoch 1, 31% \t train_loss: 0.22 took: 8.34s\n",
      "Epoch 1, 41% \t train_loss: 0.21 took: 8.80s\n",
      "Epoch 1, 51% \t train_loss: 0.21 took: 8.84s\n",
      "Epoch 1, 62% \t train_loss: 0.20 took: 8.53s\n",
      "Epoch 1, 72% \t train_loss: 0.18 took: 8.38s\n",
      "Epoch 1, 83% \t train_loss: 0.19 took: 7.75s\n",
      "Epoch 1, 93% \t train_loss: 0.18 took: 7.72s\n",
      "Validation loss = 0.18\n",
      "Epoch 2, 10% \t train_loss: 0.19 took: 8.20s\n",
      "Epoch 2, 20% \t train_loss: 0.20 took: 8.55s\n",
      "Epoch 2, 31% \t train_loss: 0.20 took: 8.79s\n",
      "Epoch 2, 41% \t train_loss: 0.19 took: 8.07s\n",
      "Epoch 2, 51% \t train_loss: 0.19 took: 8.50s\n",
      "Epoch 2, 62% \t train_loss: 0.22 took: 8.23s\n",
      "Epoch 2, 72% \t train_loss: 0.20 took: 8.00s\n",
      "Epoch 2, 83% \t train_loss: 0.19 took: 8.14s\n",
      "Epoch 2, 93% \t train_loss: 0.16 took: 8.08s\n",
      "Validation loss = 0.12\n",
      "Epoch 3, 10% \t train_loss: 0.12 took: 7.87s\n",
      "Epoch 3, 20% \t train_loss: 0.11 took: 8.07s\n",
      "Epoch 3, 31% \t train_loss: 0.10 took: 10.77s\n",
      "Epoch 3, 41% \t train_loss: 0.11 took: 8.25s\n",
      "Epoch 3, 51% \t train_loss: 0.10 took: 7.82s\n",
      "Epoch 3, 62% \t train_loss: 0.10 took: 9.04s\n",
      "Epoch 3, 72% \t train_loss: 0.10 took: 7.79s\n",
      "Epoch 3, 83% \t train_loss: 0.08 took: 8.34s\n",
      "Epoch 3, 93% \t train_loss: 0.08 took: 8.47s\n",
      "Validation loss = 0.05\n",
      "Epoch 4, 10% \t train_loss: 0.07 took: 8.87s\n",
      "Epoch 4, 20% \t train_loss: 0.07 took: 7.64s\n",
      "Epoch 4, 31% \t train_loss: 0.07 took: 7.83s\n",
      "Epoch 4, 41% \t train_loss: 0.07 took: 8.21s\n",
      "Epoch 4, 51% \t train_loss: 0.07 took: 8.32s\n",
      "Epoch 4, 62% \t train_loss: 0.06 took: 8.62s\n",
      "Epoch 4, 72% \t train_loss: 0.07 took: 8.36s\n",
      "Epoch 4, 83% \t train_loss: 0.07 took: 8.04s\n",
      "Epoch 4, 93% \t train_loss: 0.07 took: 8.35s\n",
      "Validation loss = 0.04\n",
      "Epoch 5, 10% \t train_loss: 0.06 took: 8.03s\n",
      "Epoch 5, 20% \t train_loss: 0.06 took: 7.77s\n",
      "Epoch 5, 31% \t train_loss: 0.06 took: 7.70s\n",
      "Epoch 5, 41% \t train_loss: 0.06 took: 7.58s\n",
      "Epoch 5, 51% \t train_loss: 0.07 took: 7.64s\n",
      "Epoch 5, 62% \t train_loss: 0.06 took: 7.59s\n",
      "Epoch 5, 72% \t train_loss: 0.06 took: 7.60s\n",
      "Epoch 5, 83% \t train_loss: 0.07 took: 7.62s\n",
      "Epoch 5, 93% \t train_loss: 0.06 took: 7.69s\n",
      "Validation loss = 0.05\n",
      "Epoch 6, 10% \t train_loss: 0.05 took: 7.91s\n",
      "Epoch 6, 20% \t train_loss: 0.06 took: 7.78s\n",
      "Epoch 6, 31% \t train_loss: 0.06 took: 7.76s\n",
      "Epoch 6, 41% \t train_loss: 0.06 took: 7.85s\n",
      "Epoch 6, 51% \t train_loss: 0.06 took: 8.44s\n",
      "Epoch 6, 62% \t train_loss: 0.05 took: 7.98s\n",
      "Epoch 6, 72% \t train_loss: 0.06 took: 7.89s\n",
      "Epoch 6, 83% \t train_loss: 0.06 took: 7.65s\n",
      "Epoch 6, 93% \t train_loss: 0.05 took: 7.95s\n",
      "Validation loss = 0.09\n",
      "Epoch 7, 10% \t train_loss: 0.05 took: 8.05s\n",
      "Epoch 7, 20% \t train_loss: 0.05 took: 7.79s\n",
      "Epoch 7, 31% \t train_loss: 0.05 took: 8.32s\n",
      "Epoch 7, 41% \t train_loss: 0.05 took: 7.97s\n",
      "Epoch 7, 51% \t train_loss: 0.05 took: 8.02s\n",
      "Epoch 7, 62% \t train_loss: 0.06 took: 7.86s\n",
      "Epoch 7, 72% \t train_loss: 0.05 took: 8.75s\n",
      "Epoch 7, 83% \t train_loss: 0.06 took: 8.92s\n",
      "Epoch 7, 93% \t train_loss: 0.06 took: 8.16s\n",
      "Validation loss = 0.06\n",
      "Epoch 8, 10% \t train_loss: 0.05 took: 8.28s\n",
      "Epoch 8, 20% \t train_loss: 0.05 took: 8.17s\n",
      "Epoch 8, 31% \t train_loss: 0.05 took: 7.96s\n",
      "Epoch 8, 41% \t train_loss: 0.05 took: 7.70s\n",
      "Epoch 8, 51% \t train_loss: 0.05 took: 7.85s\n",
      "Epoch 8, 62% \t train_loss: 0.06 took: 9.82s\n",
      "Epoch 8, 72% \t train_loss: 0.06 took: 8.46s\n",
      "Epoch 8, 83% \t train_loss: 0.05 took: 7.84s\n",
      "Epoch 8, 93% \t train_loss: 0.06 took: 7.69s\n",
      "Validation loss = 0.06\n",
      "Epoch 9, 10% \t train_loss: 0.05 took: 8.33s\n",
      "Epoch 9, 20% \t train_loss: 0.05 took: 8.32s\n",
      "Epoch 9, 31% \t train_loss: 0.04 took: 8.80s\n",
      "Epoch 9, 41% \t train_loss: 0.04 took: 9.10s\n",
      "Epoch 9, 51% \t train_loss: 0.05 took: 8.70s\n",
      "Epoch 9, 62% \t train_loss: 0.05 took: 7.98s\n",
      "Epoch 9, 72% \t train_loss: 0.05 took: 7.67s\n",
      "Epoch 9, 83% \t train_loss: 0.04 took: 7.71s\n",
      "Epoch 9, 93% \t train_loss: 0.04 took: 7.66s\n",
      "Validation loss = 0.04\n",
      "Epoch 10, 10% \t train_loss: 0.05 took: 8.56s\n",
      "Epoch 10, 20% \t train_loss: 0.05 took: 8.98s\n",
      "Epoch 10, 31% \t train_loss: 0.05 took: 8.57s\n",
      "Epoch 10, 41% \t train_loss: 0.04 took: 8.16s\n",
      "Epoch 10, 51% \t train_loss: 0.05 took: 9.01s\n",
      "Epoch 10, 62% \t train_loss: 0.04 took: 8.37s\n",
      "Epoch 10, 72% \t train_loss: 0.05 took: 7.95s\n",
      "Epoch 10, 83% \t train_loss: 0.05 took: 8.40s\n",
      "Epoch 10, 93% \t train_loss: 0.05 took: 7.73s\n",
      "Validation loss = 0.03\n",
      "Epoch 11, 10% \t train_loss: 0.04 took: 7.77s\n",
      "Epoch 11, 20% \t train_loss: 0.04 took: 7.59s\n",
      "Epoch 11, 31% \t train_loss: 0.05 took: 7.84s\n",
      "Epoch 11, 41% \t train_loss: 0.04 took: 8.09s\n",
      "Epoch 11, 51% \t train_loss: 0.05 took: 7.84s\n",
      "Epoch 11, 62% \t train_loss: 0.04 took: 8.16s\n",
      "Epoch 11, 72% \t train_loss: 0.04 took: 8.15s\n",
      "Epoch 11, 83% \t train_loss: 0.04 took: 8.87s\n",
      "Epoch 11, 93% \t train_loss: 0.04 took: 7.71s\n",
      "Validation loss = 0.06\n",
      "Epoch 12, 10% \t train_loss: 0.04 took: 7.89s\n",
      "Epoch 12, 20% \t train_loss: 0.05 took: 7.63s\n",
      "Epoch 12, 31% \t train_loss: 0.04 took: 7.63s\n",
      "Epoch 12, 41% \t train_loss: 0.04 took: 7.67s\n",
      "Epoch 12, 51% \t train_loss: 0.04 took: 7.55s\n",
      "Epoch 12, 62% \t train_loss: 0.04 took: 7.66s\n",
      "Epoch 12, 72% \t train_loss: 0.04 took: 8.24s\n",
      "Epoch 12, 83% \t train_loss: 0.05 took: 8.43s\n",
      "Epoch 12, 93% \t train_loss: 0.05 took: 7.71s\n",
      "Validation loss = 0.05\n",
      "Epoch 13, 10% \t train_loss: 0.04 took: 8.56s\n",
      "Epoch 13, 20% \t train_loss: 0.04 took: 8.67s\n",
      "Epoch 13, 31% \t train_loss: 0.04 took: 8.79s\n",
      "Epoch 13, 41% \t train_loss: 0.04 took: 8.74s\n",
      "Epoch 13, 51% \t train_loss: 0.04 took: 8.38s\n",
      "Epoch 13, 62% \t train_loss: 0.04 took: 8.85s\n",
      "Epoch 13, 72% \t train_loss: 0.04 took: 8.74s\n",
      "Epoch 13, 83% \t train_loss: 0.04 took: 8.21s\n",
      "Epoch 13, 93% \t train_loss: 0.04 took: 8.45s\n",
      "Validation loss = 0.03\n",
      "Epoch 14, 10% \t train_loss: 0.04 took: 7.82s\n",
      "Epoch 14, 20% \t train_loss: 0.04 took: 7.70s\n",
      "Epoch 14, 31% \t train_loss: 0.04 took: 7.64s\n",
      "Epoch 14, 41% \t train_loss: 0.04 took: 7.69s\n",
      "Epoch 14, 51% \t train_loss: 0.04 took: 7.62s\n",
      "Epoch 14, 62% \t train_loss: 0.04 took: 7.62s\n",
      "Epoch 14, 72% \t train_loss: 0.04 took: 7.65s\n",
      "Epoch 14, 83% \t train_loss: 0.04 took: 7.78s\n",
      "Epoch 14, 93% \t train_loss: 0.04 took: 8.12s\n",
      "Validation loss = 0.03\n",
      "Epoch 15, 10% \t train_loss: 0.04 took: 8.15s\n",
      "Epoch 15, 20% \t train_loss: 0.03 took: 9.08s\n",
      "Epoch 15, 31% \t train_loss: 0.04 took: 8.70s\n",
      "Epoch 15, 41% \t train_loss: 0.04 took: 8.14s\n",
      "Epoch 15, 51% \t train_loss: 0.04 took: 7.79s\n",
      "Epoch 15, 62% \t train_loss: 0.04 took: 7.72s\n",
      "Epoch 15, 72% \t train_loss: 0.04 took: 7.77s\n",
      "Epoch 15, 83% \t train_loss: 0.04 took: 7.70s\n",
      "Epoch 15, 93% \t train_loss: 0.04 took: 8.29s\n",
      "Validation loss = 0.04\n",
      "Epoch 16, 10% \t train_loss: 0.04 took: 9.00s\n",
      "Epoch 16, 20% \t train_loss: 0.04 took: 8.13s\n",
      "Epoch 16, 31% \t train_loss: 0.04 took: 8.59s\n",
      "Epoch 16, 41% \t train_loss: 0.04 took: 8.19s\n",
      "Epoch 16, 51% \t train_loss: 0.04 took: 8.08s\n",
      "Epoch 16, 62% \t train_loss: 0.04 took: 7.60s\n",
      "Epoch 16, 72% \t train_loss: 0.04 took: 8.01s\n",
      "Epoch 16, 83% \t train_loss: 0.04 took: 8.42s\n",
      "Epoch 16, 93% \t train_loss: 0.04 took: 8.09s\n",
      "Validation loss = 0.03\n",
      "Epoch 17, 10% \t train_loss: 0.04 took: 7.78s\n",
      "Epoch 17, 20% \t train_loss: 0.03 took: 7.75s\n",
      "Epoch 17, 31% \t train_loss: 0.04 took: 7.64s\n",
      "Epoch 17, 41% \t train_loss: 0.03 took: 8.29s\n",
      "Epoch 17, 51% \t train_loss: 0.04 took: 8.96s\n",
      "Epoch 17, 62% \t train_loss: 0.03 took: 8.33s\n",
      "Epoch 17, 72% \t train_loss: 0.03 took: 8.21s\n",
      "Epoch 17, 83% \t train_loss: 0.05 took: 8.64s\n",
      "Epoch 17, 93% \t train_loss: 0.04 took: 8.31s\n",
      "Validation loss = 0.03\n",
      "Epoch 18, 10% \t train_loss: 0.03 took: 8.93s\n",
      "Epoch 18, 20% \t train_loss: 0.04 took: 8.88s\n",
      "Epoch 18, 31% \t train_loss: 0.03 took: 8.73s\n",
      "Epoch 18, 41% \t train_loss: 0.04 took: 8.55s\n",
      "Epoch 18, 51% \t train_loss: 0.04 took: 7.71s\n",
      "Epoch 18, 62% \t train_loss: 0.04 took: 7.63s\n",
      "Epoch 18, 72% \t train_loss: 0.04 took: 7.68s\n",
      "Epoch 18, 83% \t train_loss: 0.04 took: 7.62s\n",
      "Epoch 18, 93% \t train_loss: 0.04 took: 7.75s\n",
      "Validation loss = 0.02\n",
      "Epoch 19, 10% \t train_loss: 0.03 took: 8.72s\n",
      "Epoch 19, 20% \t train_loss: 0.04 took: 8.23s\n",
      "Epoch 19, 31% \t train_loss: 0.04 took: 8.28s\n",
      "Epoch 19, 41% \t train_loss: 0.03 took: 8.61s\n",
      "Epoch 19, 51% \t train_loss: 0.03 took: 8.40s\n",
      "Epoch 19, 62% \t train_loss: 0.04 took: 7.65s\n",
      "Epoch 19, 72% \t train_loss: 0.04 took: 7.72s\n",
      "Epoch 19, 83% \t train_loss: 0.03 took: 7.60s\n",
      "Epoch 19, 93% \t train_loss: 0.04 took: 7.68s\n",
      "Validation loss = 0.05\n",
      "Epoch 20, 10% \t train_loss: 0.03 took: 9.52s\n",
      "Epoch 20, 20% \t train_loss: 0.04 took: 8.72s\n",
      "Epoch 20, 31% \t train_loss: 0.03 took: 7.59s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, 41% \t train_loss: 0.03 took: 7.73s\n",
      "Epoch 20, 51% \t train_loss: 0.04 took: 8.27s\n",
      "Epoch 20, 62% \t train_loss: 0.03 took: 7.92s\n",
      "Epoch 20, 72% \t train_loss: 0.04 took: 7.74s\n",
      "Epoch 20, 83% \t train_loss: 0.04 took: 9.22s\n",
      "Epoch 20, 93% \t train_loss: 0.04 took: 8.44s\n",
      "Validation loss = 0.03\n",
      "Training finished, took 2440.60s\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "n_epochs = 20\n",
    "learning_rate = 0.002\n",
    "\n",
    "n_batches = len(train_loader)\n",
    "\n",
    "loss, optimizer = createLossAndOptimizer(net, learning_rate)\n",
    "\n",
    "training_start_time = time.time()\n",
    "\n",
    "#Loop for n_epochs\n",
    "print(\"Training with {} images\".format(len(train_loader)))\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    print_every = n_batches // 10\n",
    "    start_time = time.time()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        img, pos = data\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        expected = torch.ones(len(img),2,requires_grad=False)\n",
    "        for a in range(len(img)):\n",
    "            expected[a][0] = pos[0][a]\n",
    "            expected[a][1] = pos[1][a]\n",
    "        \n",
    "        output = net(img)\n",
    "        loss_size = loss(output, expected)\n",
    "        loss_size.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss_size.data.item()\n",
    "        total_train_loss += loss_size.data.item()\n",
    "        \n",
    "        if (i + 1) % (print_every + 1) == 0:\n",
    "            print(\"Epoch {}, {:d}% \\t train_loss: {:.2f} took: {:.2f}s\".format(epoch+1, int(100 * (i+1) / n_batches), running_loss / print_every, time.time() - start_time))\n",
    "            #Reset running loss and time\n",
    "            running_loss = 0.0\n",
    "            start_time = time.time()\n",
    "            \n",
    "    total_val_loss = 0\n",
    "    for inputs, labels in val_loader:\n",
    "\n",
    "        #Wrap tensors in Variables\n",
    "        img, expected = Variable(img), Variable(expected)\n",
    "\n",
    "        #Forward pass\n",
    "        val_outputs = net(img)\n",
    "        val_loss_size = loss(val_outputs, expected)\n",
    "        total_val_loss += val_loss_size.data.item()\n",
    "\n",
    "    print(\"Validation loss = {:.2f}\".format(total_val_loss / len(val_loader)))\n",
    "\n",
    "print(\"Training finished, took {:.2f}s\".format(time.time() - training_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight [64, 3, 3, 3], but got 3-dimensional input of size [3, 256, 256] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3ff95055a967>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimg_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-e0449a098d6a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 320\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [64, 3, 3, 3], but got 3-dimensional input of size [3, 256, 256] instead"
     ]
    }
   ],
   "source": [
    "img = Image.open(\"data/test.png\")\n",
    "to_tensor = transforms.ToTensor()\n",
    "img_tensor = to_tensor(img)\n",
    "\n",
    "output = net(img_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
